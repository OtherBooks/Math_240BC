
\chapter{Eigenvalue problems}\label{Eigenvalue_problem}
\section{Eigenvalue}\label{Eigenvalue}

We first make different notations of the Laplace operator.

We assume that $M$ is a Riemannian manifold with the Riemannian metric 
%
\[ ds^2 = \sum g_{ij} d x _i d x _j .\]
%
Let $ (g^{ij}$) be the inverse matrix of $  (g_{ij}$) and let $ g = {\rm det}  (g_{ij})$. Then under the local coordinates $ (x _1, \ldots, x _n )$, we define
%
\[ \Delta = \frac{1}{\sqrt{g}} \frac{\partial }{\partial x_i} \left( g ^{ij} \sqrt{g} \frac{\partial }{\partial x_j} \right) .\]
%
Apparently, we can write 
%
\[ \Delta =   g^{ij}\frac{\partial^2 }{\partial x_i \partial x _j} +\frac{1}{\sqrt{g} } \frac{\partial }{\partial x_i} \left( g ^{ij} \sqrt{g} \right)\frac{\partial }{\partial x_j}   .  \]
%
As before, we have the following computation 
%
\begin{eqnarray*}
\lefteqn{\frac{1}{\sqrt{g} } \frac{\partial }{\partial x_i}  ( g^{ij} \sqrt{g} )} \\
&& = \frac{1}{2} g^{ij} \frac{\partial}{\partial x_i} \log g + \frac{\partial }{\partial x_i}  g ^{ij} \\
&& = \frac{1}{2} g^{ij}g^{kl}\frac{\partial g _{kl} }{\partial x_i} - g^{in} g^{jm} \frac{\partial g _{mn} }{\partial x_i} \\
&& = - g^{kl} \Gamma ^j _{kl} .
\end{eqnarray*}
Thus we also have the following formula 
%
\[ \Delta = g^{ij}   \frac{\partial^2 }{\partial x_i \partial x _j} - g ^{kl} \Gamma ^j_{kl}  \frac{\partial }{\partial x_j}   .\]
%
From the above representation, we have the following third formula for the Laplace operator.

Let $ ds^2 = \sum^n _{j=1} \omega ^2_j $. With respect to the frame, the connection $ (\omega _{ij} )$ is well-defined. We are above the define the covariant derivatives of a function like the following
%
\begin{eqnarray*}
df & = & f _i \omega _i\\
f_{ij} \omega _j & = & d f _i - f _s \omega _{si}.\end{eqnarray*}
%
Using the above notations, we can define 
%
\[ \Delta f = \sum^n_{i=1} f _{ii} = \sum _i \nabla _i \nabla _i f .\]
%
Finally, we can define the Laplace operator on $p$-forms as follows:

 Let $ d : \wedge ^p (M) \rightarrow  \wedge^{p+1} (M) $ be the ordinary differential operator, where $ \wedge ^p(M) $ be the space of smooth $p$-forms. With respect to the Riemannian metric,  $ \wedge^p(M)$ becomes an infinite dimensional inner product space.

Let $ \delta $ be the formal dual operator with respect to $d$. Then
%
\[\delta: \wedge ^p(M) \rightarrow   \wedge ^{p-1} (M). \]
%
We can {\bf prove} that $ \delta$ is also a differential operator of first order. The Laplace operator can be defined as 
%
\[ \Delta = d \delta + \delta d .\]
%
In particular, on the space of functions, or $0$-forms,
%
\[ \Delta = \delta d.\]
We have the following:

\begin{theorem}[Weitzenb\"{o}ck formula] For function $f$, we have 
%
\[ \Delta f = \delta d f = - \sum \nabla _i\nabla_i f .\]
In general, we have the following 
%
\[ \Delta = - \sum \nabla _i \nabla _i +  \ \mbox{curvature terms}\]
%
which is also called Weizenb\"{o}ck formula.

We go back to the Laplacian on functions. We know that $ \Delta = \sum \nabla _i \nabla _ i $ is well-defined on 
$ C^\infty (M)$. 

Unfortunately, with the following $ L^2$-inner product 
%
\[ \langle f \cdot g \rangle = \int _M fg d V  \]
%
$C^\infty$ (M) is not a complete metric space. The complete metric space is $ L^2(M) $. However, there is no way that we can extend $ \Delta $ on $ L^2(M) $.
\end{theorem}

\noindent{\bf Proof:}
The key point is that any differential operator is a closed-graph operator. Thus if $ \Delta $ is extendable, then by ***, $ \Delta $ has to be a bounded operator, as by the example of Heaviside function.
\qed

\begin{figure}[h!]
\vspace{0.2in}
\caption{Heaviside Function}
\end{figure}

\vspace{0.5in}

Thus we can only extend the operator into a densely defined self-adjoint operator.

Recall that an operator $ \Delta $ is self-adjoint if 
%
\[ {\rm Dom} (\Delta) = {\rm Dom} ( \Delta ^\ast) \]
and 
\[ \langle \Delta f , g \rangle = \langle f, \Delta g \rangle \]
for any $ f, g \in {\rm Dom} (\Delta)$.

In functional analysis, we have the following theorem.
Let 
\[ Q (\varphi, \psi)= \int \nabla \varphi \nabla \psi.\]
%
Then $Q$ is a non-negative quadratic form defined on $ H^1_0 (M)$. Then there is a unique densely defined operator $A$ such that 
%
\[ Q (\varphi, \psi) = - ( A \varphi , \psi). \]
%
Such an operator $A$ is in fact called the Dirichlet Laplacian operator.

As an exercise, we prove that on an only manifold $ L^2$ harmonic function must be constant.
\qed

\begin{theorem}
Let $ A $ be the Dirichlet extension of the Laplacian $\Delta $.  A function $f$ is called $A$-harmonic, if $ f \in {\rm Dom} (A) $ and $A f = 0 $. If $ f \in L^2 (M)$, then $f$ is a constant.
\end{theorem}

\noindent{\bf Proof:} The key point is that 
%
\[ Q (\rho ^2 f, f) = Q \langle  \rho^2 f , \Delta f \rangle = 0 .\]
Thus using the same method as before, $f $ is a constant.
If $ M$ is a compact manifold with no boundary,  we still use $\Delta$ to denote the Dirichlet extension of the Laplace operator. By the elliptic regularity, the spectrum of $ \Delta $ are discrete.  That is, there is a sequence
%
\[ 0 = \lambda _0 < \lambda _1  \leq \lambda _2 \leq \ldots \]
%
such that for any $\lambda_i$,  there $\exists f_i , f _i \in L^2 $
%
\[ \Delta f _i = - \lambda _i f_i. \]


We have similar results for manifolds with boundary conditions. To be more precise, the Laplacians acting on 
functions with the following boundary conditions.

\begin{enumerate}
  \item [(A)] Dirichlet boundary condition: $\Delta$ acting on $f$ vanishing on the boundary.
  \item [(B)] Neumann boundary condition: $ \Delta $ acting on functions such that $ \frac{\partial f}{\partial n} = 0 $.
 \end{enumerate}  
  
For eigenvalues, we have the following minimax principle. Assume that $M$  is a closed manifold, then
%
\[ \lambda _1 = \inf_{\int f = 0 } \frac{\int |\nabla f|^2}{\int f^2}.\]
%
To prove the above result, we let $ \varphi $ be any smooth function such that 
%
\[ \int_M \varphi = 0 .\]
%
Then by the definition of $ \lambda _1 $, we have 
%
\[\frac{\int | \nabla (f + \varepsilon \varphi )|^2}{\int (f + \varepsilon \varphi )^2} \geq \lambda _1 .\]
%
However, if we take the first order term, we get 
%
\[\int (\delta f + \lambda _1 f ) \varphi = 0 .\]
Note that 
%
\[ \int (\Delta f + \lambda _ 1 f ) = 0 .\]
%
Then 
%
\[\Delta f + \lambda _1 f \equiv 0 \]
%
and $ \lambda _ 1 $ is the first eigenvalue.

By elliptic regularity, $ \lambda _ 1 > 0 $. Thus we have the following Poincar\'{e}-inequality: there exists a constant $C$, such that 
%
\[\int | \nabla f |^2 \geq C \int f^2 \]
for any function with 
%
\[ \int _M f = 0 .\]
%
Before going further, let's prove the following co-area formula.
\qed

\begin{theorem} Let $M$ be a compact Riemannian manifold with boundary. Let $ f \in H^\prime (M)$. Then 
%
\[ \int _M g = \int ^{+ \infty}_{-\infty} \int _{ \{ f = 0 \}} \frac{g}{| \nabla f |} d \sigma. \]
\end{theorem}

\noindent{\bf Proof:}
Without loss of generality, we assume that  $ | \nabla f | \neq 0 $. Thus by the implicit function theorem $ \{ f = \sigma \} $ is a smooth manifold. 


Using the cut-off function, we may assume that $ {\rm supp}\,  g $ is contained in a coordinate chart. Thus we may assume that the Riemannian metric is given under the global coordinates $(x_1, \ldots, x _n) $ as follows 
%
\[ d s^2 = \sum g _{ig} d x _i ds _j \]
%
by definition  
%
\[ \int _M g = \int_M g \sqrt{{\rm det} (g _{ij} ) } \ dx_1, \ldots, dx _n. \]
%
Since $ \nabla f \neq 0 $, we can solve the equation 
%
\[ f = \sigma \]
%
by 
%
\[ x_1 = x_1 (\sigma , x_2, \ldots, x_n) \]
or in other words, by the implicit function theory $ (\sigma, x_2 , \ldots, x_n ) $ is a local coordinate system as well. The Jacobian of the transformation is 
%
\[ d x_1 \wedge \ldots \wedge d x _n = \frac{\partial x _1}{\partial \sigma} d \sigma \wedge d x_2 \wedge \ldots \wedge d x_n .\]
On the other side, restricting to $ f = \sigma $, the Riemann metric can be written as 
%
\[\left(g_{11} \frac{\partial x _1}{\partial x_k} \cdot \frac{\partial x _1}{\partial x_l} + g_{1l} \frac{\partial x _1}{\partial x_l } + g _{k1} \frac{\partial x _1}{\partial x_k} + g _{kl}\right) \, d x _k d x _l.\]
%
If we choose local coordinates such that $ g_{kl} = \delta _{kl} $. Then we have 
%
\[\left( \frac{\partial x _1}{\partial x_k} \cdot \frac{\partial x _1}{\partial x_l} + \delta _{kl} \right) \, d x_k dx_l .\]
%
The volume form of the above is 
%
\begin{eqnarray*} 
\lefteqn{{\rm det} \left( \delta _{kl} + \frac{\partial x _1}{\partial x_k} \cdot \frac{\partial x _1}{\partial x_l} \right) = 1 + \sum \left|\frac{\partial x _1}{\partial x_k}\right| ^2}\\
&& = \frac{1}{| \frac{\partial f}{\partial x_1}|^2} \sum\left|\frac{\partial f}{\partial x_k}\right|^2 = \frac{|\nabla f |^2}{ | \frac{\partial f}{\partial x_1} | ^2} .
\end{eqnarray*}
%
Thus we have 
%
\begin{eqnarray*}
\int_M g & = & \int_M g \sqrt{{\rm det} (g_{ij})} d x _1 \ldots d x _n \\
 &= & \int_M \sqrt{{\rm det} (g_{ij})} \frac{\partial x_1}{\partial \sigma} d \sigma  \wedge d x_2 \ldots \wedge d x _n .
\end{eqnarray*}
%
By ($\triangle$), we must have  
%
\[ d V ds^2 = d V _{f = \sigma} \cdot  \frac{     \left|\frac{{\partial f }}{{\partial x_i}}\right|}{| \nabla f |}      .\]
%
Thus
%
\[ \int_M g = \int ^{+ \infty}_{-\infty} \left( \int _{f=\sigma} \frac{g}{|\nabla f|}\right) d \sigma. \]
 %
Of course, in general, there are points such that $ \nabla f = 0 $. But by a theorem of Sand, the set 
%
\[ \left\{ yf(y) | \nabla f (y) = 0 \right\} \]
%
is of zero measure. Using the standard covering technique, we can prove the same result.

As an application of the above co-area formula, we prove the following result of Sobolev inequality.

\medskip

\noindent{\bf Sobolev inequality.} Let $M$ be a compact manifold with boundary. Then there is a constant $ C> 0 $ such that 
%
\[ C \left( \int_M |f| ^{\frac{n}{n-1}} \right)^{\frac{n-1}{n}}\leq \int_M |\nabla f | \]
for any smooth function $ f /2M = 0 $ ($D$-condition) or $ \int f = 0 $ (Neumann condition).

\medskip

\noindent{\bf Isopermetric inequality.} Let $ \Omega $ be a domain in $M, \Omega \subset \subset M$. Then there is a constant independent to $ \Omega $ such that 
%
\[ C {\rm vol} (\Omega ) ^{\frac{n-1}{n}} \leq {\rm vol} (\partial \Omega). \]

We want to prove that the Isopermetric inequality is equivalent to the Sobolev inequality.

At least one-side of the implication was clear: assuming the Sobolev inequality, if we let 
%
\[ f _\varepsilon (x) = \left\{ \begin{array}{cl} 1 & x \in \Omega , \ d (x , \partial \Omega ) \geq \varepsilon \\
\frac{d(x, \partial \Omega }{\varepsilon} & x \in \Omega , \ d (x , \partial \Omega ) \leq \varepsilon\\
0 &  {\rm otherwise} \end{array} \right\}. \]
Then using the Sobolev inequality, the isopermetric inequality follows by letting $ \varepsilon \rightarrow 0 $.

In order to prove that the isopermetric inequality implies the Sobolev inequality, we use the co-area formula. We assume that $ f \geq 0 $. Then 
%
\[ \int_M | \nabla f| = \int ^\infty_0  \ \mbox{Area} \  (f = \sigma ) \, d \sigma .\]
%
We also have 
%
\begin{eqnarray*}
\int_M |f|  ^{\frac{n}{n-1}} & =& \int ^\infty_0 {\rm vol} ( f ^{\frac{n}{n-1}}> \lambda ) \, d \lambda \\
& = &  \frac{n}{n-1}\int^\infty_0 {\rm vol} (f > \sigma ) \sigma ^{\frac{n}{n-1}} d \sigma .
\end{eqnarray*}
%
Using the isopermetric inequality, we have 
%
\[ \int_M |\nabla f| = \int ^\infty _0 {\rm Area} (f = \sigma ) \, d \sigma \geq C \int^\infty _0 {\rm vol} (f > \sigma ) ^{\frac{n}{n-1}} d \sigma.\]
Thus in order to prove the Sobolev inequality, we just need to prove that 
\[ \int ^\infty _0   {\rm vol} (f > \sigma ) ^{\frac{n}{n-1}} d \sigma \geq C \left( \int ^\infty _0 {\rm vol}  (f > \sigma ) \sigma ^{\frac{n}{n-1}} d \sigma \right) ^{\frac{n}{n-1}} .\]
We let 
\begin{eqnarray*}
 F(\sigma) & = & {\rm vol} (f > \sigma) \\
\varphi (t) & = & \int^t_0 F(\sigma) ^{\frac{n}{n-1}} d \sigma \\
\psi (t) & = &  \left( \int ^t _0 F(sigma ) \sigma ^{\frac{n}{n-1}} d \sigma \right) ^{\frac{n-1}{n}}. \end{eqnarray*}
%
Then $ \varphi (0) = \psi (0) $. Using the monotonicity of $ F(\sigma) $ we can prove that 
%
\[ \varphi ^\prime (t) \geq  \frac{n}{n-1} \psi^\prime (t) .\]
%
Thus
%
\[ \varphi (\infty) \geq \frac{n}{n-1} \psi (\infty) .\]

\begin{corollary}
\[ \left( \int  f  ^{\frac{n-p}{np}}\right) ^{\frac{np}{n-p}}  \leq C\left( \int |\nabla f |^p \right) ^{\frac{1}{p}}\]
for any $ p > 1$.
\end{corollary}
\begin{definition} Let $M$ be a compact Riemannian manifold if $ \partial M \neq \emptyset$.
%
\[ h_D (M) = \inf \left\{ \left.\frac{{\rm vol} ( \partial \Omega )}{{\rm vol} ( \Omega)} \right| \Omega \subset \subset M\right\}\]
if $  \partial M = \emptyset$.
%
\[ h_N = \inf  \left\{ \left.\frac{{\rm vol}( H )}{\min ({\rm vol} (M_1), {\rm vol} (M_2) )} \right| H \ \mbox{is a hypersurface} \right\}.\]
%
\end{definition}
\begin{theorem}[Cheeger] For Dirichlet condition, we have 
%
\[ \lambda _ 1 \geq \frac{1}{4} h^2_D. \]
%
For Neumann condition
%
\[ \lambda _1 \geq \frac{1}{4} h^2_N (M) .\]
\end{theorem}

\noindent {\bf Proof:} We only prove the case for Dirichlet condition. We first observe that, if there is a constant $\mu$ such that 
%
\[ \int_M |\nabla \varphi | \geq \mu \int_M |\varphi | \]
%
for any  $ \varphi $ with $ \varphi |_{\partial M} = 0 $. Then $ \lambda _1 \geq \frac{1}{4} \mu^2 $. To 
see this, we consider $ \varphi = f^2 $ 
%
\[ \mu \int _M f^2 \leq 2 \int_M |f| | \nabla f|\leq 2 \left( \int_M f^2 \right) ^{\frac{1}{2}} \left( \int |\nabla f|^2 \right) ^{\frac{1}{2}}.\]
%
Thus
%
\[ \frac{1}{4} \mu^2 \int_M f ^2 \leq \int_M | \nabla f|^2.\]
%
Since the above is true for any function $f$, we must have 
%
\[ \lambda _1 \geq \frac{1}{4} \mu ^2 .\]
%
Finally, we prove a result which is well known but can't readily be found in the literature.
\qed

\begin{theorem} Let $M$ be a compact manifold with smooth boundary. Let 
%
\[ M_1 = \inf_{\int f = 0} \frac{\int | \nabla f|^2}{\int f ^2} .\]
%
Then we have the following result: let $f$ be a minimizer, and let $f$ be smooth. Then
%
\[\frac{\partial f }{\partial n} = 0. \]
\end{theorem}

\noindent {\bf Proof:} Let $ \varphi $ be a smooth function with compact support such that 
%
\[ \int \varphi = 0. \]
%
Then we have 

\[ \int |\nabla (f + \varepsilon \varphi )|^2 \geq \mu_1 \int (f + \varepsilon \varphi )^2 .\]
%
Thus we have
%
\[ \int \nabla f \nabla \varphi = - \mu _1 \int_M f \varphi.\]
%
by Green's formula
%
\[ \int_M \nabla f \nabla \varphi - \int _{\partial M} \varphi \frac{\partial f }{\partial n} - \int_M \Delta f \varphi.\]
%
Thus since $ \Delta f = - \mu_1 f $, we have 
%
\[ \int_{\partial M} \varphi\frac{\partial f }{\partial n}  = 0 \]
%
and we must have $ \frac{\partial f }{\partial n}  = 0 $.

\qed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%4
\section{Eigenvalue problems(II)}\label{Eigenvalue_II}

By the variational characterizing of the eigenvalues, we know that it is usually more difficult to get the lower bound estimate of eigenvalues. Among all the eigenvalues, the lower bound of the first eigenvalue is particularly important.

The Cheeger's result did give a lower bound estimate of the first eigenvalues. But the bounds are not ``computable.'' In geometry, ``computable'' bounds provide effective versions of Poincar\'{e} and Sobolev inequalities.

The following Lichnerowicz theorem gives a good lower bound of the first eigenvalue for closed manifold.

\begin{theorem}[Lichnerowicz] Let $ M$ be a closed $n$-dimensional Riemannian manifold. Assume that 
%
\[ {\rm Ric} (M) \geq (n-1) k > 0 \]
%
Then $ \lambda _1 \geq n k $
\end{theorem}

\noindent{\bf Proof:}
One line proof: let $ u$ be the first eigenfunction. Then using the Ricci identity we have 
%
\[ \frac{1}{2} \Delta |\nabla u|^2 \geq \sum u _{ij} ^2 + \nabla u \Delta u + {\rm Ric}(\nabla u, \nabla u). \]
%
We have 
%
\begin{eqnarray*} \sum u^2_{ij} &\geq & \sum u^2 _{ii} \geq \frac{1}{2} \left(\sum u_{ii} \right) ^2  
= \frac{\lambda_1^2}{n} uU^2 \\
{\rm Ric} (\nabla u, \nabla u) & \geq & (n-1) k |\nabla u |^2 
\end{eqnarray*}
\qed

Thus we have 
%
\[\frac{1}{2} \Delta |\nabla u|^2 \geq  \frac{\lambda ^2_1}{n} u^2 - \lambda _1 |\nabla uU |^2 +  (n-1)k | \nabla u|^2 .\]
%
Taking integration on both sides, we get 
%
\[  \frac{\lambda ^2_1}{n} - \lambda ^2_1 + (n-1) k \lambda _1 \leq 0 .\]
%
The theorem follows.

In 1962, Obata proved, if $ \lambda _1 = nk $, then $ M$ has to be the standard sphere. 

For the rest of this section, we use the gradient estimates to find ``computable'' lower bounds of the first eigenvalue.

We prove the following theorem.

\begin{theorem}[Li-Yau] Let $M$ be a closed manifold and 
\end{theorem}
\[ {\rm Ric} (M)\geq 0.\]
%
Then $ \lambda _ 1 \geq \pi ^2 / 2 d ^2 $, $d$ is the diameter.

\noindent{\bf Proof:}
Let  $ u$ be the first eigenfunction. After normalization we may assume that 
%
\[ 1 = \sup u > \inf u = - k \geq -1\]
for some $ 1 \geq k > 0 $. Let 
%
\[ \tilde{u} = \frac{u - \frac{1-k}{2}}{\frac{1+k}{2}}.\]
Then after this linear change of $u$. We have 
%
\[ \left\{ \begin{array}{l} \Delta \tilde{u} = - \lambda _1 ( \tilde{u} + 1 )\\
\sup \tilde{u} = a \\
\inf \tilde{u} = - 1 
\end{array}\right.\]
% 
for $ a = \frac{1-k}{1+k} $.  $ 1 > a \geq 0 $.

Let $ g = \frac{1}{2} ( | \nabla \tilde{u} |^2 + ( \lambda _ 1 + \varepsilon ) \tilde{u} ^2) $ for some  $ \varepsilon > 0 $ to be determined later. Assume that at $ x _0$ 
%
\[ g(x_0) = {\rm Max}\, g.\]
Using the maximum principle, at $ x_0 $, we have 
%
\[ \tilde{u}_j \tilde{u}_{j} + (x_1 + \varepsilon ) \tilde{u} u _i = 0 \]
and
\begin{eqnarray*}
0 \geq \Delta g & = & \hat{u} ^2 _{ij}   {\rm Ric} ( \nabla \tilde{u}, \nabla \tilde{u} ) + \nabla \tilde{u} \nabla \Delta \tilde{u} \\
 && + ( \lambda _1 + \varepsilon ) |\nabla \tilde{u}|^2 + ( \lambda _1 + \varepsilon ) \tilde{u} \Delta \tilde{u}\\
&&\geq \tilde{u}^2 _{ij} - \lambda _1 |\nabla \tilde{u}|^2 + ( \lambda _1 + \varepsilon ) |\nabla \tilde{u}|^2 \\
&& - \lambda _1 (\lambda _1 + \varepsilon ) \tilde{u} ( \tilde{u} + a  
\end{eqnarray*}
%
if at $ x _0 , \nabla \tilde{U} = 0 $. Then we have 
%
\[ |\nabla \tilde{u}|^2 + ( \lambda _1 + \varepsilon ) \tilde{u} ^2 \leq ( \lambda _1 + \varepsilon ). \]

In particular, we have 
%
\[ |\nabla \tilde{u} |^2 + \lambda _1 (1+a ) \tilde{u} ^2 \leq (1+a )\]
if $ \nabla \tilde{u} (x_0) \neq 0$. Then using the Cauchy inequality 
%
\[ \tilde{u} ^2 _{ij} \geq \frac{(\tilde{u} _i \tilde{u}_j \tilde{u}_{ij} )^2}{|\nabla \tilde{u}|^4} = ( \lambda _1 + \varepsilon )^2 \tilde{u} ^2 .\] 
%
Thus we have 
\begin{eqnarray*}
0 \geq \Delta g (x_0) & \geq & ( \lambda _1 + \varepsilon )^2 \tilde{u}^2 + \varepsilon |\nabla \tilde{u}|^2\\
&& - \lambda _1 (\lambda _1 + \varepsilon) \tilde{u}^2 - \lambda _1 (\lambda _1 + \varepsilon )\\
&& \geq 2 \varepsilon g - \lambda _1 (\lambda _1 + \varepsilon )a.
\end{eqnarray*}
%
For any $ \varepsilon > \lambda _1 a $, the above gives 
\[ |\nabla \tilde{u}| ^2 + \lambda _1 (1 + a) \tilde{u}^2 \leq \lambda _1 (1 + a). \]
Let 
%
\[ f(t) =  {\rm arc} \sin \tilde{U} ( \sigma (t)) \]
%
where $ \sigma (t) $ is the arc-length curve connecting the minimal point and the maximum point of $ \tilde{u} $. Then by the above argument, we have 
%
\[ |f^\prime (t)|\leq \sqrt{\lambda _1 (1 + a) } .\]
%
Let $d$ be the diameter of the manifold, then we have 
%
\begin{eqnarray*} d \sqrt{\lambda_1 (1+a)} & \geq & \int ^d _0 ( f ^\prime (t) ) d t \geq  {\rm arc}  \sin 1 \\
&& - {\rm arc} \sin (-1) = \pi.
\end{eqnarray*}
Thus 
%
\[ \lambda +1 \geq \frac{1}{1+a} \frac{\pi^2}{d^2}.
\]
Since $ a < 1$, this gives
\[ \lambda_1 \geq \frac{\pi^2}{2d^2} \]
%
We let $ \theta =  {\rm arc} \sin \tilde{u}$. Then Zhong-Yau proved $ \oint $ the following surprising theorem.

\begin{theorem}[***] Let 
%
\[ \psi   (\theta) = \left(\frac{4}{\pi} \right)\theta + \cos \theta \sin \theta ) - 2 \sin \theta. \]
%
Then 
\[ \frac{|\nabla \tilde{u}|^2}{1 - \tilde{u}^2} \leq \lambda _1 (1 + a \psi (\theta))   . \]
%
The method is maximal principle, very surprising and mysterious.

Using the above sharpened inequality, observed that  $ \psi (\theta) $ is an odd function, we can prove that 
%
\[ \lambda _1 \geq \frac{\pi^2}{d^2}. \]
%

Assume that $ {\rm Ric} (M) \geq - (n-1) k $ for $ k > 0 $. Then by estimating $ | \nabla u|^2 + \lambda _1 ( 1 - u )^2 $, Li-Yau was able to prove that 
%
\[ \lambda _1 \geq \frac{C}{d^2} \exp ( - C_1 \sqrt{kd^2}).\]
%
*** was able to modify the above and proved that 
%
\[ \lambda _1 \geq \frac{\pi^2}{d^2} \exp ( - C_1 \sqrt{kd^2}).\]

When $ {\rm Ric}(M) > 0 $, or $ {\rm Ric}(M) \geq (n-1) k > 0 $ the above inequality is not optimal. In fact, it is far from being optimal. Let $ M = s ^n $. Then by Lichnerowicz theorem, $ \lambda _1\geq n $ (in fact, $ \lambda _ 1 = n $).
 $ d (s^n) = \pi $. Thus $ **$ gives 
%
\[\lambda _1 \geq 1 .\]
In this direction, we have the following Peter Li Conjecture.
\end{theorem}

\begin{conjecture}[P. Li] If $ {\rm Ric} (M) \geq (n-1) k $.  Then
%
\[ \lambda _ 1 \geq \frac{\pi^2}{d^2} + (n-1)k .\]
\end{conjecture}
Such a conjecture, if true, will sharpen both the result of Zhong-Yang and Lichnerowicz because by Myer's theorem
%
\[ \frac{\pi^2}{d^2} \geq k. \]
%
Not much was known to the proof of the conjecture. D. Yang proved that 
%
\[\lambda _1 \geq \frac{\pi^2}{d^2} + \frac{1}{4} ( n-1) k\]
%
Ling Jun proved a bigger number 
%
\[\lambda _1 \geq \frac{\pi^2}{d^2} + \alpha ( n-1) k  \alpha > \frac{1}{4} .\]
%
On the other end, if $ {\rm Ric} (M) \geq ( n-1) k, k > 0 $. Then 
%
\[ \lambda _1 \geq \frac{\pi^2}{d^2} - ( n-1) k.\]
%
Recently, *** was able to prove that 
%
\[ \lambda _1 > \frac{\pi^2}{d^2} .\]
Very interesting result.

We end this section by citing a result of Li and Croke.
\begin{theorem} Let $M$ be a $ \oint $ manifold, with boundary. Then there is a constant $ C = (n, d, V, k ) > 0 $ such that the Sobolev constant is $ > c > 0 $. 
\end{theorem}

\sectionFirst_eigenvalue}


Let $M$ be an $n$-dimensional Riemannian manifold with or without boundary. Let
the metric $ds^2$ be represented by
\[
ds^2 = \sum g_{ij}dx_idx_j,
\]
where $(x_1,\cdots,x_n)$ are local coordinates. Let
\[
\Delta = \frac{1}{\sqrt{g}}\sum\frac{\partial}{\partial x_i}(g^{ij}\sqrt{g}
\frac{\partial}{\partial x_j})
\]
be the Laplace operator, where $(g^{ij})=g_{ij}^{-1}$, $g=\det (g_{ij})$.
\\

The operator $\Delta$ acts on smooth functions. If $\partial M \neq \emptyset$,
then we may define one of  the following two boundary conditions:
\begin{itemize}
\item[\ding{172}.] Dirichlet condition: $f|_{\partial M} = 0$.
\item[\ding{173}.] Neumann condition: 
$\frac{\partial f}{\partial n}|_{\partial M} = 0$, where $n$ is the outward
normal vector of the manifold $\partial M$.
\end{itemize}

By the elliptic regularity, if $M$ is compact, then the spectrum of $\Delta$
consists of eigenvalues
\[
\lambda_1 \leqslant \lambda_2 \leqslant \cdots \leqslant \lambda_k \rightarrow
+\infty
\]
of  finite multiplicity.
\\

By the variational principal, we have the following Poincar\'{e} inequality
\[
\int|\nabla f|^2 \geqslant \lambda_1\int f^2
\]

To our special interests, we would like to give
``computable" lower bound estimates of the first eigenvalue. Here by 
``computable" we mean the geometric quantities like the diameter, the bounds of 
the curvature, \textit{etc}, that are readily available.
\\

Li-Yau~\cite{li-yau} discovered the method of gradient estimates to give ``computable" lower
bounds of the first eigenvalue. The prototype of the estimates is as follows:
\begin{theorem}
[Li-Yau] Let $M$ be a compact manifold without boundary. Let $d$ be the diameter
of $M$. Assume that the Ricci curvature of $M$ is non-negative. Then we have
the following estimate
\[
\lambda_1 \geqslant \frac{\pi^2}{4d^2}.
\]
\end{theorem}


{\bf Proof.}
Let $u$ be the first eigenfunction such that
\[
\max u^2 = 1.
\]
Let
\[
g(x) = \frac{1}{2}(|\nabla u|^2 + (\lambda_1 + \varepsilon)u^2),
\]
where $\varepsilon > 0$.
\\

The function $g$ is a smooth function. Let $x_0$ be the maximal point of $g$. 
Then at $x_0$ we have
\begin{equation}\label{1-1}
u_j u_{ji} + (\lambda_1 + \varepsilon) u u_i = 0
\end{equation}
and
\[
0 \geqslant u_{ji}^2 + u_j u_{jii} + (\lambda_1 + \varepsilon)
|\nabla u|^2 + (\lambda_1 + \varepsilon)u\Delta u.
\]
Using the Ricci identity, we have
\[
u_j u_{jii} = u_j(\Delta u)_j + Ric(\nabla u) \geqslant u_j(\Delta u)_j.
\]
Thus we have
\begin{equation}\label{2-1}
0 \geqslant u_{ji}^2 + u_j(\Delta u)_j + (\lambda_1 + \varepsilon)
|\nabla u|^2 + (\lambda_1 + \varepsilon)u\Delta u.
\end{equation}
Suppose that  at the maximum point of $g(x)$, $\nabla u \neq 0$. Then we have
\[
u_{ji}^2 \geqslant |\nabla u|^{-4}(\sum_{i,j}u_j u_i u_{ij})^2
\]
by the Cauchy inequality. Using the first order condition, we conclude
\[
u_{ji}^2 \geqslant (\lambda_1 + \varepsilon)^2 u^2.
\]
Putting the above inequality into $\circledast$, we get
\[
0 \geqslant \varepsilon|\nabla u|^2 + \varepsilon(\lambda_1 + \varepsilon)u^2
\]
which is not possible. Thus at the maximum point, we must have $\nabla u = 0$.
Therefore we have
\[
g(x) \leqslant \frac{1}{2}(\lambda_1 + \varepsilon)\max u^2 = \frac{1}{2}
(\lambda_1 + \varepsilon).
\]
From the above estimate, we get
\[
\frac{|\nabla u|^2}{1-u^2} \leqslant \lambda_1 + \varepsilon.
\]
Since $\varepsilon$ is arbitrary, we let it go to zero and obtain
\[
\frac{|\nabla u|^2}{1 - u^2} \leqslant \lambda_1.
\]
By changing the sign of $u$, we may assume that $\max u = 1$. Let $u(p) = 1$ for
$p\in M$. Since $\int u = 0$, there is a point $q\in M$ such that $u(q)=0$. Let
$\sigma(t)$ be the minimal geodesic line connecting $q$ and $p$. Consider the
function
\[
\arcsin u(\sigma(t))
\]
By the above inequality, we get
\[
|(\arcsin u(\sigma(t)))'| \leqslant \sqrt{\lambda_1}|\sigma '(t)|
\]
Integrating the above inequality along the geodesic line, we get
\[
\frac{\pi}{2} \leqslant \sqrt{\lambda_1}d
\]
and the theorem is proved.


\qed

Several extensions of the above method can be obtained when
\begin{itemize}
\item[\ding{172}] The manifold has boundary;
\item[\ding{173}] The Ricci curvature has a lower bound.
\end{itemize}

We first address the Neumann boundary condition.
\begin{lemma}
If $\partial M \neq 0$ and $\partial M$ is convex, then $g(x)$ doesn't attain
its maximum on $\partial M$ unless at the point $\nabla u=0$.
\end{lemma}

{\bf Proof.}
Let $x_0 \in \partial M$ such that $g(x)$ attains the maximum at $x_0$. Then
\[
\frac{\partial g(x_0)}{\partial n} \leqslant 0,
\]
where $\vec{n}$ is the outward unit normal vector. By the definition of $g(x)$
and the fact $\frac{\partial u}{\partial n} = 0$, we have
\[
u_j\frac{\partial u_j}{\partial n} \leqslant 0.
\]
Let $h_{ij}$ be the second fundamental form. Then
\[
0 \geqslant u_j\frac{\partial u_j}{\partial n} = h_{ij} u_i u_j \geqslant 0.
\]
If the equality is true, then we must have $\nabla u(x_0) = 0$. 

\qed


The next question is to sharpen the Li-Yau estimates. Even for the unit circle,
Li-Yau estimate is not sharp.
\\

Let's consider the circle $x^2 + y^2 = R^2$. Let the parameter, or the 
coordinate, of the circle be
\[
x = R\cos \theta, y = R\sin \theta
\]
Then the Laplace operator is
\[
\frac{1}{R^2}\frac{\partial^2}{\partial\theta^2}
\]
As a result, $u = \cos\theta, \sin\theta$ are the two eigenfunctions with the
first eigenvalue $1/R^2$. If $u = \cos\theta$, then with the induced Riemannian
metric,
\[
|\nabla u|^2 = \frac{1}{R^2}\sin^2\theta.
\]
Thus we have
\[
g(\theta) = \frac{1}{2R^2},
\]
and thus
\[
\frac{|\nabla u|^2}{1 - u^2} \leqslant \lambda_1,
\]
which is not sharp.
\\

The problem is that in general, we don't know whether the first eigenfunction is
always symmetric. More precisely, if we assume that
\[
1 = \sup u > \inf u = -k \geqslant -1
\]
we don't know whether $k = 1$. From Li-Yau's basic estimate, we can improve the
estimate $\lambda_1 \geqslant \pi^2/4d^2$ to
\[
\lambda_1 \geqslant (\frac{\pi}{2} + \arcsin k)^2 d^{-2}.
\]
The above inequality is essentially useless because we know nothing about $k$.
However, using a simple trick, we can double the estimate of Li-Yau:
\\

Take
\[
\widetilde u = \frac{u - \frac{1-k}{2}}{\frac{1+k}{2}}.
\]
Then using the standard gradient estimate, we get
\begin{equation}\label{3}
|\nabla \widetilde u|^2 \leqslant \lambda_1(1+a)(1-\widetilde u^2)
\end{equation}
where
\[
a = \frac{1-k}{1+k}.
\]
Now the function $\widetilde u$ is symmetric: 
$\max\widetilde u=-\min\widetilde u = 1$. Using the same method, we get
\[
\lambda_1 \geqslant \frac{\pi^2}{(1+a)d^2} \geqslant \frac{\pi^2}{2d^2}
\]

Zhong-Yang~\cite{zhong-yang} took one more step and proved the following result.
\begin{theorem}
[Zhong-Yang] Let $M$ be a compact Riemannian manifold with non-negative Ricc
curvature. Then
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2}.
\]
\end{theorem}

\qed

The estimate is called ``optimal" in the sense that for $1$ dimensional 
manifold, the lower bound is achieved. We shall soon see that the estimate, in 
general, is far from being optimal.
\\

The basic idea of the proof is still the maximum principle. From the estimate~\eqref{3}, we suspect that there is an odd function $\varphi(\arcsin u)$
such that
\begin{equation}\label{4}
|\nabla\widetilde u|^2 \leqslant \lambda_1(1+a\varphi(\arcsin u))
(1 - \widetilde u^2).
\end{equation}
If such function $\varphi$ exists, then we have
\[
\sqrt{\lambda_1}d \geqslant \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}
\frac{d\theta}{\sqrt{1+a\varphi(\theta)}} \geqslant \pi
\]
by the convexity of the function $\frac{1}{\sqrt{1+x}}$, which implies the optimal inequality.
\\

To prove the inequality~\eqref{4}, we use the maximal principle. At the point
$x_0$ such that the equality of~\eqref{4} holds, we have
\[
\varphi(\arcsin u) \leqslant \widetilde u - \widetilde u 
\sqrt{1 - \widetilde u^2}\varphi '(\arcsin u) + \frac{1}{2}
(1 - \widetilde u^2)\varphi''(\arcsin u).
\]
We define a function
\[
\psi(\theta) = \left\{
\begin{array}{ll}
(\frac{4}{\pi}(\theta + \cos\theta\sin\theta)-2\sin\theta)\cos^{-2}\theta, &
\theta\in(-\frac{\pi}{2}, \frac{\pi}{2}) \\
\psi(\frac{\pi}{2}) = 1, \psi(-\frac{\pi}{2}) = -1
\end{array}
\right..
\]
Then a straightforward computation gives
\[
\left\{\begin{array}{l}
\psi '(\theta) \geqslant 0 \\
\psi - \sin\theta + \sin\theta\cos\theta\psi ' - 
\frac{1}{2}\cos^2\theta\psi'' = 0
\end{array}
\right..
\]
Using the maximum principle we get $\varphi(\arcsin u) \leqslant \psi(\arcsin u)$. 
Since $\psi$ is an odd function, the theorem is proved.
\\

\begin{remark}
Recently, Hang-Wang~\cite{hang-wang} proved that, in fact,
\[
\lambda_1 > \frac{\pi^2}{d^2}
\]
unless the manifold is of one dimensional.
\end{remark}

The Li-Yau-Zhong-Yang estimate is still effective when the Ricci curvature is
not ``too negative". Namely, let
\[
Ric(M) \geqslant -(n-1)K
\]
for some constant $K>0$.
Then
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2} - (n-1)K.
\]
Thus as long as the right hand side of the above is positive, the estimate is
effective.
\\

When $K$ is very negative, we need to modify the basic gradient estimate. The
following theorem belongs to Li-Yau.
\begin{theorem}
Let $M$ be a compact Riemannian manifold without boundary. Assume that
\[
Ric(M) \geqslant -(n-1)K
\]
for $K>0$. Then
\[
\lambda_1 \geqslant \frac{1}{(n-1)d^2}\exp(-[1 + (1 + 4(n-1)^2 d^2 K)^{1/2}]),
\]
where $d$ is the diameter of $M$.
\end{theorem}

{\bf Proof.}
Let $u$ be the normalized first eigenfunction. That is
\[
1 = \sup u > \inf u \geqslant -1.
\]
Let $\beta > 1$. Consider
\[
G(x) = \frac{|\nabla u|^2}{(\beta - u)^2}.
\]
Let $x_0$ be the maximum point of $G(x)$. Then
\[
\nabla G(x_0) = 0, \Delta G(x_0) \leqslant 0.
\]
Since
\[
G(x)(\beta - u)^2 = |\nabla u|^2,
\]
we have
\[
\Delta G(\beta - u)^2 +2\nabla G \nabla(\beta-u)^2 + G\Delta(\beta - u)^2
= \Delta|\nabla u|^2.
\]
Thus at $x_0$, we have
\begin{eqnarray}
\nonumber 0 & \geqslant & \Delta |\nabla u|^2 - G \Delta (\beta - u)^2 \\
\nonumber & = & 2\sum u_{ij}^2 + 2\sum u_i u_{ijj} - 2G[(\beta - u)(-\Delta u) + 
|\nabla u|^2] \\
\nonumber & = & 2u_{ij}^2 + 2u_i(\Delta u_i)_i \\
\nonumber & + & 2Ric(\nabla u, \nabla u) - 
2G[\lambda_1 u (\beta - u) + |\nabla u|^2].
\end{eqnarray}
That is
\[
u_{ij}^2 - \lambda_1 |\nabla u|^2 - (n-1)K|\nabla u|^2
- G(\lambda_1 u (\beta - u) + |\nabla u|^2) \leqslant 0.
\]
We choose a local coordinate system at $x_0$ such that $u_j = 0$ 
$(j=2,\cdots,n)$, $u_1 = |\nabla u|$. Then $u_1 \neq 0$ (or otherwise, 
$G(x_0) = 0$ which is not possible). From $\nabla G(x_0) = 0$, we have
\[
\left\{\begin{array}{l}
u_{11} = -|\nabla u|^2 (\beta -u)^{-1} \\
u_{1i} = 0, i \neq 1
\end{array}
\right..
\]
Using the following trick
\begin{eqnarray}
\nonumber \sum_{i\cdot j=2}^n u_{ij}^2 & \geqslant & 
\sum_{i=2}^n u_{ii}^2 \geqslant \frac{1}{n-1}\left(\sum_{i=2}^n u_{ii}\right)^2
 = \frac{1}{n-1}(\Delta u - u_{11})^2 \\
\nonumber & = & \frac{1}{n-1}(\lambda u + u_{11})^2 = 
\frac{1}{n-1}(\lambda^2 u^2 + 2\lambda u u_{11} + u_{11}^2) \\
\nonumber & \geqslant & \frac{u_{11}^2}{2(n-1)} - \frac{1}{n-1}\lambda^2 u^2,
\end{eqnarray}
 we have
\[
\frac{1}{2(n-1)}\frac{|\nabla u|^4}{(\beta - u)^2} - \frac{\lambda^2 u^2}{n-1}
- (\lambda_1 + (n-1)K)|\nabla u|^2 - \lambda_1\frac{|\nabla u|^2 u}{\beta - u}
\leqslant 0.
\]
Let $\alpha = u(\beta - u)^{-1}$. Then
\[
\alpha \leqslant \frac{1}{\beta - u} \leqslant \frac{1}{\beta - 1}.
\]
Thus
\[
\frac{1}{2(n-1)}G^2 - \frac{\lambda^2}{n-1}\alpha^2 - (\lambda_1 + (n-1)K)G
-\lambda_1 G\alpha \leqslant 0,
\]
which gives 
\[
G(x) \leqslant G(x_0) \leqslant 4(n-1)
\left(\frac{\lambda\beta}{\beta-1} + (n-1)K\right).
\]
Let $l$ be the geodesic line connecting $x_1$ and $x_2$, where $u(x_1) = 0$,
$u(x_2) = \sup u = 1$. Then we have
\[
\log\frac{\beta}{\beta - 1} \leqslant \int_\gamma \frac{|\nabla u|}{\beta - u}
\leqslant \left[4(n-1)\left(\frac{\beta\lambda_1}{\beta-1}+(n-1)K\right)\right]^{1/2}d,
\]
or in other words
\[
\lambda_1 \geqslant \frac{\beta-1}{\beta}\left[\frac{1}{4(n-1)d^2}
\left(\log\frac{\beta}{\beta - 1}\right)^2 - (n-1)K\right]
\]
Choosing $\beta_0$ such that the right side above maximized, we proved the
theorem.

\qed



The optimal estimate, in this direction, was obtained by Yang:
\begin{theorem}
Let $M$ be a compact Riemannian manifold. 
\[
Ric(M) \geqslant -(n-1)K,\ \ (K > 0),\ \ d = diam(M)
\]
Then
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2}\exp(-C_n K d^2)
\]
where $C_n = \sqrt{n-1}$ for $n>2$ and $C_n = \sqrt{2}$ for $n=2$.
\end{theorem}

The case when the Ricci curvature is positive is also very interesting. The
following theorem of Lichnerowicz is well known.
\begin{theorem}
Let $M$ be a compact Riemannian manifold. Assume that $d$ is the diameter of the manifold and 
\[
Ric(M) \geqslant - (n-1) K > 0.
\]
for $K>0$. Then
\[
\lambda_1 \geqslant nK.
\]
\end{theorem}

\qed



In seeking the common generalization of the above theorem and the Zhong-Yang
estimate, Peter Li (see~\cite{yangd}) proposed the following conjecture.
\begin{conjecture}
For a compact manifold with $Ric(M) \geqslant (n-1)K > 0$ the first eigenvalue
$\lambda_1$, with respect to the closed, the Neumann, or the Dirichlet Laplacian
satisfies
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2} + (n-1)K.
\]
\end{conjecture}
Here is $\partial M \neq \emptyset$, we assume that $\partial M$ is convex.
\\

Note that by Myer's theorem, we always have $\pi^2/d^2 \geqslant K$. Thus the
conjecture, if true, will give a common generalization of the result of
Lichnerowicz's and the one obtained by the gradient estimate.
\\

In this direction, D-G Yang~\cite{yangd} proved that the first Dirichlet eigenvalue of the
Laplacian satisfies
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2} + \frac{1}{4}(n-1)K,
\]
if the manifold has weakly convex boundary. He also proved that the first closed
eigenvalue and the first Neumann eigenvalue of the Laplacian satisfies
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2} + \frac{1}{4}(n-1)K,
\]
if the manifold has convex boundary.
\\

Ling~\cite{ling} was able to improve the above estimate into
\[
\lambda_1 \geqslant \frac{\pi^2}{d^2} + \frac{31}{100}(n-1)K
\]
Further improvements are possible, see Ling-Lu~\cite{ling-lu} for example.
\\

We end this lecture by making the following
\\

\begin{conjecture}
Let $M$ be a compact Ricci flat Riemannian manifold such that
\[
\lambda_1 - \frac{\pi^2}{d^2} < \varepsilon
\]
for a sufficiently small $\varepsilon > 0$. Then $M = S' \times M_0$, where 
$M_0$ is a Ricci flat compact Riemannian manifold.
\end{conjecture}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%




\section{The lower bound of $ \lambda_2 - \lambda _1$}\label{Eigenvalue_gap}

Let $ \Omega $ be a smooth bounded domain in $ \mathbb{R}^n , \lambda _1 \lambda _2 $ be the first two eigenvalues with respect to the Dirichlet boundary condition. Then 
%
\[ \lambda _2 - \lambda _1 \geq \frac{\bar{\pi}^2}{4 d ^2} \]
%
where $ d $ is the diameter.

\noindent{\bf Proof.} Let $ u_2, u_1 $ be the second and the first eigenfunctions, respectively. By the variational principle, we must have $ u_1 (x) > 0 $. Furthermore, near the boundary, we must have $ \nabla u_1 (x) \neq 0 $. Thus the function


\[ v = \frac{u_2}{u_1} \]
%
is smooth up to the boundary. By a simple computation, we obtained 
%
\[ \Delta v = - \lambda v - 2 ( \nabla v \cdot \nabla \log u_1) \]
%
where $ \lambda = \lambda _2 - \lambda _1 > 0 $. Let $ G$ be the function $ \bar{\Omega} \rightarrow \mathbb{R}$
%
\[G = |\nabla v | ^2 + \lambda (u - v ) ^2 \; \mu > \sup v. \]
%
Then $ G$ is a smooth function. Let $ x_0 \in \bar{\Omega} $ be the maximum point of $G$. Then we claim that 
%
\[ G \leq \sup_{\Omega} \lambda ( u - v )^2 .\]

In fact, if $ x_0 \in \partial \Omega $. By choosing an orthonormal frame $ \{ \ln_1 , \ldots, \ln_n \} $ such that $ \ln_1$ be the out normal direction if we let $ \frac{\ln_1}{\partial \Omega} = \frac{\partial }{\partial x _1} $. Then
%
\[ \frac{\partial G}{\partial x _1} (x_0)  = 2 \sum^n_{i=1} v_i v_{i1} -  2 \lambda v _1 (\mu - v ). \]
%
We claim that
%
\[ \frac{\partial G}{\partial x _1} (x_0) \geq 0. \]
%
To see this, we first observed that $\frac{\partial v }{\partial x _1} = 0 $. This can be proved using the variational principle. Thus
%
\[\frac{\partial G}{\partial x _1} (x_0)  = 2 \sum^n_{i=2} v_i v_{i1}.\]
%
Using the definition of the second fundamental form, we get 
%
\[ v _{i1} = - \sum h_{ij} v _j .\]
%
Thus we have 
%
\[0 \leq \frac{\partial G}{\partial x _1} (x_0)  = -2 \sum   h_{ij} v_{j}.\]
%
Since $ \Omega $ is assumed to be convex, all $ v_i = 0 $. Thus 
%
\[ G(x) \leq \sup_{x \in \bar{\Omega}} \lambda ( \mu - v )^2 .\]
Next we assume that $ x_0 \in \Omega $. Then at the maximum point, we have 
%
\[ \nabla G (x_0) = 0 , \; \Delta G (x_0) \leq 0 .\]
We apply the standard gradient estimate: assume that at $ x_o, \nabla v \neq 0 $. Then we have 
%
\begin{eqnarray*}
 0 &= &G_i (x_0) = 2 v_j v_{ji} - 2  \lambda ( \mu - v ) v _i \\
0 \geq \Delta G &= &2 \sum v ^2 _{ij} + 2 v _j v_{jii} + 2 \lambda \sum v ^2_i - 2 \lambda ( \mu - v) \sum v_{ii} .
\end{eqnarray*}
%
Since $ \nabla v \neq 0 $, we can choose local orthonormal frame such that  $ v _1 \neq 0 , v _i = 0 (i > 1)$. Thus at $ x_0$, we have 
\begin{eqnarray*}
&& v _{11} (x_0) = \lambda ( \mu - v ) \\
&& v_{i1} (x_0) = 0 \;  2 \leq i \leq n .
\end{eqnarray*}
%
Thus 
%
\[ 0 \geq \Delta G = 2 \sum v^2_{ij} + 2 \lambda ( \mu - v) v - 4 v ^2_1 (\log u_1 ) _{11}.\]
%
Using a result of Brascamp and Lieb, $ \log u_1$ is a concave function. Thus $ (\log u) _{11} (x_0) \leq 0 $. Thus
%
\[ \sum v ^2 _{ij} + \lambda ^2 ( \mu - v) \nu \leq 0 \]
%
or, in other words,
%
\[ v^2_{11} + \lambda ^2 v (\mu - v ) |_{x_{0}} \leq 0 .\]
%
which is not possible. Thus we must have $ \nabla v = 0 $ at $ x_0$ and thus
%
\[ G(x) \leq \sup \lambda ( \mu - r) ^2 .\]
%
We have 
%

\[\sqrt{\lambda} \geq \frac{|\nabla v |^2}{\sqrt{(\sup v - \inf v )^2 - (\sup v - v )^2}} .\]
%
Using the same method as in the estimate of the first eigenvalue, we get 
%
\[ \lambda _1 \geq \frac{\pi^2}{4d^2}.\]
%
\begin{remark}
Using the method of Zhong-Yang, Zhong-Yu was able to modify the above estimate to 
%
\[ \lambda _2 - \lambda _1 \geq \frac{\pi^2}{d^2}.\]
\end{remark}
However, even the above estimate is not optimal. Van de Berg (see also Yau, Problem session) conjectured that 
%
\[ \lambda _2 - \lambda _1 \geq \frac{3\pi^2}{d^2}.\]
The estimate is asymptotically accurate for a very thin rectangular.

Not much progress was made in the direction of this conjecture. In JFA, 176, 368--399 (2000). Banuelos and Mendez-Hernandez proved that if $ \Omega  $ is a convex domain in $ \mathbb{R} ^2 $ which is symmetric with respect to both $ x $- and $y$-axises, then the Van der Berg conjecture is true.

For a triangle, Lu and Rowlett proved the following.

\begin{theorem} Let $ \triangle $ be a triangle and let $ d = d (\triangle) $ be the diameter of $ \triangle$. That is, $d$ is the longest side of the triangle. Then $ \forall  C > 0 $.
\[ ( \lambda _2 (\triangle ) - \lambda _1 (\triangle )) d^2 (\triangle ) \leq C \]
%
is a compact set.
\end{theorem}
\noindent{\bf Proof.} 
When a sequence of triangles doesn't converge, then the smallest angle must go to zero. We assume that the smallest angle is $ \alpha \pi$ and we assume that the diameter $ d = 1$. 
\qed


\begin{figure}[h!]
\vspace{0.2in}
\caption{Figure}
\end{figure}

The key part of the proof is the following cutting lemma. Let $ P_1, P_2 $ be two points on $BC$ such that 
%
\[ | P_1 C| = \alpha ^3 , \; |P_2 C |= 2 \alpha ^\varepsilon \]
%
where $ \varepsilon > \frac{2}{q} $. For the sake of simplicity, we assume that $ < A CB = \pi/2$. We are going to prove that the eigenvalues of $ABC$ and $A \theta_2 P_2 C $ are almost the same, thus cutting an acute angle won't make too much difference.

We let $U - A \theta _1 P_1 C $ and $ U^\prime = A \theta _2 P_2 C $.

Let $ f_i$ be the eigenfunctions for $ \lambda _i = \lambda _i (ABC), i = 1, 2$. The height of $ V = ABC \backslash U$ is at most 
%
\[ ( 1 - \alpha ^\varepsilon ) \tan \alpha \pi\approx (1 - a ^\varepsilon ) a .\]
%
Above we have dropped a constant factor of $ \pi$ on the right side for simplicity in the arguments to follow. By the one-dimensional Poincar\'{e} inequality
%
\[\frac{\int _u {|\nabla f_i|^2}}{\int_V f_i^2 } \geq \frac{1}{( 1 - \alpha ^\varepsilon )^2 \alpha ^2} \frac{\int _{V^{\prime}}  |\nabla f_i|^2}{\int_{V^{\prime}} |f_i|^2 } \geq \frac{1}{( 1 - 2 d ^\varepsilon )^2 \alpha ^2}  \]
%
where as before  $ V = ABC\backslash U , V ^\prime = ABC \backslash V^\prime $. 

On the other hand, we always have 
%
\[\frac{\int_u | \nabla f _i|^2}{\int_u f_i^2 } \geq \frac{1}{\alpha^2} , \; \frac{\int_{u^{\prime}} | \nabla f _i|^2}{\int_{u^{\prime}} f_i^2 }\geq \frac{1}{\alpha^2} .\]
We normalize $ f_i$ to be 
%
\[\int_{ABC} f _i ^2 = 1 .\]
%
Let 
%
\[\int _V f_i^2 = \beta .\]
%
Then by  the variational principle, we have 
%
\[ \frac{\beta}{(1- a ^{\varepsilon} )^2 \alpha ^2} + \frac{1-\beta}{\alpha ^2} \leq \int_V | \nabla f_i |^2 + \int_u |\nabla f _i |^2 = \lambda _i .\]
%
By the asymptotic estimate of the eigenvalues using  the Bessel functions, we have 
%
\[ \lambda _i (ABC) \sim \frac{1}{\alpha^2} + \frac{C_2 }{\alpha ^\frac{4}{3}}.\]
%
Therefore we have 
%
\[ \beta \leq \frac{\alpha ^{\frac{2}{3}} C_2 ( 1 - \alpha ^\varepsilon )^2}{\alpha ^\varepsilon ( 2 - \alpha ^\varepsilon)} \leq \frac{C_2}{2} \alpha ^{\frac{2}{3} - \varepsilon}.\]
%
For simplicity in the arguments to follow, we will replace the constant factor $ C_2 / 2 $ by a constant factor 1, since we are considering $ \alpha \rightarrow 0 $.

Let $\rho $ be a smooth compactly supported function so that 
%
\[ \rho |_v \equiv 1, \; \rho |_{v^{\prime }}  \equiv 0 .\]
%
We may also assume that 
%
\[ | \nabla \rho | \leq \frac{1}{d ^\varepsilon} , |\Delta \rho |, | \Delta \rho^2 |\leq \frac{1}{d ^{ 2 \varepsilon }}.\]
%
For the arguments to follow, we use the sign convention for Euclidean Laplacian so that $ - \Delta $ has positive spectrum. Note that 
%
\[ - ( \rho f_i) \Delta ( \rho f_i) = \lambda _i \rho ^2 f _i ^2 - f _i ^2 \rho \Delta \rho - 2 f _i \rho \nabla \rho \nabla f _i.\]
%
In the estimates to follow, we will absorb all constants multiplying factors of $ a ^\delta $ for $ \delta > 0 $ into a factor of one, since it is clear that as $ \alpha \rightarrow 0$, no generality is lost by this assumption.

1. Estimate for $ \lambda _i (v ^\prime) $. We may use $ \rho f_i $ as a test function for the Rayleigh quotient on $ v ^\prime $ to estimate $ \lambda _1 (v^\prime) $ for above. By ($\star$), we have 
%
\[\lambda_1 (v ^\prime) \leq \lambda _1 (ABC) + \frac{\int_{v^{\prime}} - \rho \Delta \rho f _1^2 - 2 \rho \nabla \rho f _1 \nabla f_1}{\int _{v^{\prime}} \rho ^2 f ^2_1} .\]
%
Since 
%
\[ \int _{v^{\prime}} \rho \nabla \rho f _1 \nabla f_1 = \frac{1}{2} \int _{v^{\prime}} \nabla \rho^2 \nabla f_1^2 = - \frac{1}{2} \int _{v^{\prime}} \Delta \rho^2   f_1^2\]
%
and $ \nabla \rho, \Delta \rho = 0 $ on $ v $, we must have 
%
\[ \int _{u^{\prime}} -\rho \Delta \rho f _1^2 - 2  \rho\nabla \rho f_1  \nabla f _1 \leq  \frac{1}{d^{2 \varepsilon}} \int _{v^{\prime} - v}   f _1^2 \leq  \alpha ^{\frac{2}{3} - 3 \varepsilon}.\]
%
Noting that 
%
\[\int _{u^{\prime}}  \rho ^2 f ^2_1 \geq \int_u \rho^2 f ^2_1 \geq 1 - \beta \geq 1 - \alpha ^{\frac{2}{3} - \gamma}\]
%
we then have
\[ \lambda _1 (v^\prime) \leq \lambda _1 (ABC) + \frac{\alpha ^{\frac{2}{3} - 3 \varepsilon}}{1 - \alpha _{\frac{2}{3} - \varepsilon}} \leq \lambda _1 (ABC) + \alpha ^{ \frac{2}{3} -  3 \varepsilon}. \]
%
By modifying the above argument, we are able to prove that 
%
\[ \lambda _2 (v ^\prime) - \lambda _2 (ABC) \leq \alpha ^{ \frac{2}{3} -  3 \varepsilon}  + ( \lambda _2 - \lambda _1) \alpha ^{ \frac{2}{3} -  3 \varepsilon}.  \]
%
Solving the above inequality, we have 
%
\[ \lambda _2 - \lambda _1 \geq \lambda _2 (v ^\prime) - \lambda _1 ( v ^\prime) - 0 (\alpha ^{ \frac{2}{3} -  3 \varepsilon} ).\]
%
By the gap theorem, and using the fact that the diameter of $ v ^\prime $ is at most $ 4 \alpha ^\varepsilon $, we get 
%
\[ \lambda _2  (v ^\prime) - \lambda _1 ( v ^\prime)  \geq \frac{\pi^2}{16 \alpha ^{2 \varepsilon}}\]
the compactness theorem follows.

\section{Spectrum gap of the first two eigenvalues}\label{Spectrum_gap}

\subsection{Heat flow proof of a theorem of Brascamp-Lieb}
The following result was first proved by Brascamp-Lieb~\cite{blieb}. In Singer-Wong-Yau-Yau~\cite{swyy}, a simplified proof was given.
In this subsection, we give a heat flow proof.

\begin{theorem}
Let $\Omega$ be a bounded convex domain of $\mathbb{R}^n$. Let $u$ be the first
Dirichlet eigenfunction with the eigenvalue $\lambda_1$. Then (up to a sign),
$u$ is positive and $\log u$ is concave.
\end{theorem}

We begin by the following lemmas.
%\setcounter{lemma}{0}
\begin{lemma}
Up to a sign, $u \geqslant 0$.
\end{lemma}
{\bf Proof.}
Otherwise, we may use $|u|$ in place of $u$, From Kato's inequality, we have
\[
|\nabla|u|| \leqslant |\nabla u|.
\]
Thus we have
\[
\frac{\int |\nabla|u||^2}{\int u^2} \leqslant \frac{\int |\nabla u|^2}{\int u^2}.
\]
By the variational characterizing of the first eigenvalue, we know that the
right side of the above is minimized. Thus the equality must hold and $|u|$ is an
eigenfunction of the first eigenvalue.
\\

The multiplicity of the first eigenfunction must be one. Thus up to a sign, the
eigenfunction must be non-negative.
\qed

\begin{lemma}
$u > 0$ inside $\Omega$.
\end{lemma}
{\bf Proof.}
If not, assume that $u(x_0) = 0$ at a point $x_0$ in the interior of $\Omega$.
Let
\[
u(x) = p^N(x) + O(x^{N+\varepsilon})
\]
be the Taylor's expansion of the eigenfunction at $x_0$, where $p^N(x)$ is the
polynomial of degree $N$. From the equation $\Delta u = -\lambda_1 u$, we have
$\Delta p^2(x) = 0$. Since $u(x) \geqslant 0$, we must have $p^2(x)\geqslant 0$,
a contradiction to the maximal principal.
\qed

\begin{lemma}
Using the above notations, we have
\[
\frac{\partial u}{\partial n} < 0
\]
on $\partial\Omega$, the boundary of $\Omega$.
\end{lemma}
{\bf Proof.}
This follows from the strong maximum principle. By the above lemma, we have
\[
\frac{\partial u}{\partial n} \leqslant 0
\]
If $\frac{\partial u}{\partial n} = 0$, then since the function $u$ vanishes on
the boundary, we have $\nabla u = 0$ at the point. Using the Taylor's expansion
for the boundary point, we get $p^2 \geqslant 0$ and $\Delta p^2 = 0$. Since $p^2$ is harmonic, by the
strong maximum principle, $\partial p^2/\partial n < 0$ unless $p^2 =0$. But if
$p^2 \equiv 0$ then $u \equiv 0$. This completes the proof.
\qed


\qed


We now consider the heat flow
\[
\frac{\partial u}{\partial t} = \Delta u + \lambda_1 u,
\ \ u|_{\partial\Omega} = 0.
\]
we have
\begin{lemma}
For any smooth initial function $u_0 > 0$, the flow exists and converges to the
first eigenfunction.
\end{lemma}
{\bf Proof.}
Let
\[
u_1 = \sum a_j f_j(x),
\]
where $f_j(x)$ is the eigenfunction of the $j$-th eigenvalue. Then the solution
of the equation is
\[
u(t, x) = \sum a_j e^{-(\lambda_j-\lambda_i)t}f_j(x)
\]
Obviously, we have
\[
\lim_{t\rightarrow\infty} u(t,x) = a_1 f_1(x).
\]

If we choose $u_0$ such that $a_1 \neq 0$, then the flow converges to the first
eigenfunction. $f_1(x) > 0$ by the above lemmas. By our choice of $u_0$
\[
a_1 = \int_{\Omega} u_0 f_1(x) > 0.
\]
The proof is complete.
\qed

\begin{lemma}
Let $w$ be any smooth positive function on $\Omega$ such that
\[
w|_{\partial\Omega} = 0 \mbox{ and } \nabla w|_{\partial\Omega} \neq 0
\]
Then near the boundary of $\Omega$, $\log w$ is concave.
\end{lemma}
{\bf Proof.}
Since $w$ is a smooth function vanishes on the boundary, it can be viewed as the
defining function of $\Omega$. By the implicit function theorem, we solve the
equation
\[
w(x_1, \cdots, x_n) = 0
\]
to get the function
\[
x_n = x_n(x_1, \cdots, x_{n-1}).
\]
If $\Omega$ is convex, then
\[
\frac{\partial^2 x_n}{\partial x_i \partial x_j} > 0,
\]
is a positive definite matrix. Using the chain rule, the above inequality is
equivalent to
\[
-\frac{w_{ij}}{w_n} + \frac{w_{in} w_j}{w_n^2} + \frac{w_{jn} w_i}{w_n^2}
-\frac{w_i w_j w_{nn}}{w_n^3} > 0.
\]
where $1\leqslant i, j \leqslant n-1$. However, if we allow $i$ or $j$ to be
$n$, then as the $n\times n$ matrix, we still have
\[
-\frac{w_{ij}}{w_n} + \frac{w_{in}w_j}{w_n^2} + \frac{w_{jn}w_i}{w_n^2}
-\frac{w_i w_j w_{nn}}{w_n^3} \geqslant 0.
\]
Moreover, for any $(a_1, \cdots, a_n)$, if $\sum a_j w_j = 0$, we have
\[
-w_{ij} a_i a_j \geqslant \varepsilon |a|^2
\]
for some positive $\varepsilon > 0$. A generic vector has the form $a+\mu b$,
where $b = (w_1, \cdots, w_n)$. For $w$ small enough, we have
\[
-w_{ij}(a_i + \mu b_i)(a_j + \mu b_j) + \frac{1}{w} |\mu|^2 |b|^4 > 0.
\]
Thus $\nabla^2\log w$, whose matrix entries are
\[
\frac{w_{ij}}{w} - \frac{w_i w_j}{w^2},
\]
is negative definite for $w$ small enough.
\qed

\begin{remark}
The above proof is purely elementary. We can use differential geometry to give
another proof. Assume $e_1, \cdots, e_n$ are the local frame fields at the
boundary point such that $e_n$ is normal to the boundary and the rest are
tangent to the boundary. Then for $1\leqslant i, j \leqslant n-1$, we have
\[
\nabla^2 (e_i,e_j) w = e_i(e_j(w)) - \nabla e_i e_j w = h_{ij} 
\frac{\partial w}{\partial n},
\]
where $h_{ij}$ is the second fundamental form, and $\frac{\partial}{\partial n}$
is the outward normal vector field. Thus 
$\frac{\partial w}{\partial n} \leqslant 0$. To prove
\[
\frac{w_{ij}}{w} - \frac{w_i w_j}{w^2}
\]
is negative definite, we write $V=V_1 + \mu e_n$, where $V_1$ is tangent to
$\partial\Omega$. Then there is a constant $C$ such that
\[
\nabla^2 \log w(V,V) \leqslant w^{-1}\left|\frac{\partial w}{\partial n}\right|
(\pi(V_1, V_1) + C \mu \|V_1\| +C \mu^2) - 
w^{-2} \mu^2 \left|\frac{\partial w}{\partial n}\right|^4.
\]
Since $\frac{\partial w}{\partial n} \neq 0$, for points sufficient close to the
boundary, $w$ is small enough. Using the Cauchy inequality, we can prove the
above negativeness.
\end{remark}

Now we begin to prove the theorem: We will choose a function $u_0$ such that
$u_0 > 0$ and $\log u_0$ is concave. Then we shall prove that the log-concavity
is preserved under the heat flow. The theorem thus follows from the above
lemmas.
\\

To construct the required $u_0$, we first pick up any smooth function $w>0$ on
$\Omega$ with $w|_{\partial\Omega} = 0$, $\nabla w|_{\partial \Omega} \neq 0$.
Let
\[
u_0 = w e^{-C\sum x_j^2}
\]
for a constant $C > 0$ sufficiently large. By the above lemma, the function is 
log-concave near the boundary. Away from the boundary, since $w > \delta > 0$
for some constant $\delta > 0$, we can choose $C$ large enough so that $u_0$ is
log-concave.
\\

Using the matrix version of the maximum principle, we can prove that the flow
keeps the log-concavity. Let $\varphi = \log u$, where $u$ is the solution of
the heat equation
\[
\frac{\partial u}{\partial t} = \Delta u + \lambda_1 u.
\]
The flow of $\varphi$ is
\begin{equation}\label{2-1}
\frac{\partial\varphi}{\partial t} = \Delta\varphi - |\nabla\varphi|^2 - 
\lambda_1.
\end{equation}
By the maximum principle, if $T$ is the first time the matrix $\nabla^2\varphi$
is generated, then there is an $x_0\in M$ and a direction $i$ such that
\[
-\varphi_{ii} = 0
\]
and for other $j$'s, $-\varphi_{jj} \geqslant 0$. Moreover, at $x_0$,
$\varphi_{iik} = 0$, $\frac{\partial\varphi_{ii}}{\partial t} \leqslant 0$ and
$\Delta\varphi_{ii} \geqslant 0$.
\\

Differentiating~\eqref{2-1}  by $i,i$, we have
\[
0 \geqslant \frac{\partial\varphi_{ii}}{\partial t} = \Delta\varphi_{ii} - 
2\varphi_k\varphi_{kii} - 2\varphi_{ki}^2 \geqslant -2\varphi_{ki}^2.
\]
By the convexity, $\varphi_{ki}^2 \leqslant \varphi_{ii}\varphi_{kk} = 0$. Thus
$\varphi_{ki} = 0$ for $k\neq i$. The theorem follows from the strong maximum
principle.
\\

This completes the proof of the Brascamp-Lieb theorem.

\qed

\subsection{Gap of the first two eigenvalues}

For the sake of simplicity, we only consider bounded smooth domain in 
$\mathbb{R}^n$.
\\

Let $\Omega$ be a bounded domain in $\mathbb{R}^n$ with smooth boundary. Let
$\lambda_1, \lambda_2$ be the Dirichlet first two eigenvalues. Since $\lambda_1$
must be simple (of multiplicity one) we have
\[
\lambda_2 - \lambda_1> 0.
\]
The question we would like to answer is that, how to get the lower bound 
estimate of $\lambda_2 - \lambda_1$?
\\

Let $\varphi_1, \varphi_2$ be the eigenfunctions with respect to 
$\lambda_1, \lambda_2$. We set
\[
\varphi = \frac{\varphi_2}{\varphi_1}.
\]
Then a straightforward computation gives
\[
\Delta\varphi + \partial\nabla\log\varphi_1\nabla\varphi = -\lambda\varphi,
\]
where $\lambda = \lambda_2 - \lambda_1$. Moreover, since 
$\varphi_1|_{\partial\Omega} = 0$, we must have
\[
\left.\frac{\partial\varphi}{\partial n}\right|_{\partial\Omega} = 0.
\]

We have a notion of Bakry-\'Emery Ricci tensor. Let
\[
f = \varphi_1^2
\]
Then the Bakry-\'Emery Laplacian is defined as
\[
\Delta f = \Delta + \nabla\log f\nabla
\]
which is a self-adjoint operator with respect to the volume form 
$\varphi_1^2 dV$.
\\

The Bakry-\'Emery Ricci tensor is defined as
\[
-\nabla^2 \log f
\]
By the Brascamp-Lieb theorem, the Barkey-Emery Ricci curvature is non-negative.
\\

We make the following conjecture:
\begin{conjecture}
The method of gradient estimates can be generalized to the Bakry-\'Emery case
without additional difficulties.
\end{conjecture}

The above conjecture, if true, will give a unified proof between the estimation
of the first eigenvalue and gap estimate.
\\

We can go one more step further. Since the Barkey-Emery Ricci tensor comes from
the setting $(M, ds^2, e^f dV)$, which can be considered as the limit of the
wrap product
\[
e^f dr^2 + ds^2
\]
we make the following definition.
\\

Let
\[
\Omega_\varepsilon = \{(x,y)|x\in \Omega, 
0\leqslant y \leqslant \varepsilon \varphi_1^2(x)\}.
\]
Let $\mu_\varepsilon$ be the first Neumann eigenvalue. Then
\begin{conjecture}\label{conj4}
Using the above notations, we have
\[
\lambda_2 - \lambda_1 = \lim_{\varepsilon\rightarrow 0} \mu_\varepsilon.
\]
\end{conjecture}

Similarly, we make the following
\begin{conjecture}
Let $(\mu_\varepsilon)^k$ be the $k$-th Neumann eigenvalue of 
$\Omega_\varepsilon$. Then
\[
\lim_{\varepsilon\rightarrow 0}(\mu_\varepsilon)^k = \lambda_{k+1} - \lambda_1.
\]
\end{conjecture}

We can prove the following
\begin{theorem}
\[
\lambda_2 - \lambda_1 \geqslant \lim_{\varepsilon\rightarrow 0}\mu_\varepsilon.
\]
\end{theorem}
{\bf Proof.}
We first note that 
$\frac{\partial h}{\partial n}|_{\partial\Omega_\varepsilon} = 0$ on the part
$y = \varepsilon\varphi_1(x)^2$ can be written as
\[
\nabla h(\varepsilon\nabla\varphi_1^2, -1) = 0.
\]
We define $\widetilde{U}_\varepsilon$ as follows
\[
\widetilde{U}_\varepsilon = \varphi + y^2 \nabla\log\varphi_1\nabla\varphi.
\]
Then a straightforward computation gives
\[
\left\{\begin{array}{rcl}
\Delta\widetilde{U}_\varepsilon + \lambda\widetilde{U}_\varepsilon & = &
O(\varepsilon^2) \\
\left.\frac{\partial\widetilde{U}_\varepsilon}{\partial n}
\right|_{\partial\Omega_\varepsilon} & = & O(\varepsilon^2)
\end{array}
\right..
\]
From the above, we have
\[
\int_{\Omega_\varepsilon}\widetilde{U}_\varepsilon = O(\varepsilon^2).
\]
Let $\alpha$ be a number such that
\[
\int_{\Omega_\varepsilon}(\widetilde{U}_\varepsilon - \alpha) = 0.
\]
Then $\alpha = O(\varepsilon)$. By the variational principle, we have
\[
\mu_\varepsilon \leqslant 
\frac{\int_{\Omega_\varepsilon}|\nabla\widetilde{U}_\varepsilon|^2}
{\int_{\Omega_\varepsilon}(\widetilde{U}_\varepsilon - \alpha)^2}.
\]
However, since
\[
\int_{\Omega_\varepsilon}\widetilde{U}_\varepsilon^2 \geqq C\varepsilon.
\]
We have
\[
\mu_\varepsilon \leqslant 
\frac{\int_{\Omega_\varepsilon}\lambda\widetilde{U}_\varepsilon^2}
{\int_{\Omega_\varepsilon}\widetilde{U}_\varepsilon^2} + O(\varepsilon).
\]
and the theorem is proved.
\qed


\qed


\begin{remark}
We consider the wrap product
\[
e^f dr^2 + d^2
\]
over $\Omega_\varepsilon$, we see the relation between two settings. This also
gives the relation between the Barkey-Emery geometry with respect to the
ordinary Riemannian geometry.
\end{remark}

Some applications.
\begin{theorem}
[Singer-Wong-Yau-Yau, Yu-Zhong] Let $\Omega$ be a convex domain in $\mathbb{R}^n$. Then
\[
\lambda_2 - \lambda_1 \geqslant \frac{\pi^2}{d^2}.
\]
\end{theorem}
{\bf Proof.}
We consider the domain $\Omega_\varepsilon$ and let $U_\varepsilon$ be the first
Neumann eigenfunction. By what we proved in the last lecture, we have
\[
\mu_\varepsilon \geqslant \frac{\pi^2}{d_\varepsilon^2}
\]
where $d_\varepsilon$ is the diameter of $\Omega_\varepsilon$. Since 
$d_\varepsilon\rightarrow d$, the theorem is proved.
\qed

\textbf{Question}: How to recover the recent result of Yau? We are going to use
the following result of Chen-Li.

\begin{theorem}
Let $M$ be an $m$-dimensional domain in $\mathbb{R}^m$. Let $M$ be star-shaped.
Let $R$ be the radius of the largest ball centered at $p\in M$ contained in $M$
and let $R_0$ be the smallest ball centered at $p$ containing $M$. Then there is
a constant $C$, depending only on $m$, such that
\[
\eta_1 \geqslant C\frac{R^m}{R_0^{m+2}}
\]
\end{theorem}

Let $U_\varepsilon$ be the first Neumann
eigenfunction of $\Omega_\varepsilon$. Then asymptotically we can write
\[
U_\varepsilon \sim \varphi + y^2 \nabla\log \varphi_1 \nabla\varphi
\]
In general, power series method can be used to prove the conjecture.

\begin{remark} Conjecture~\ref{conj4} was proved by Lu-Rowlett~\cite{lu-rowlett}.
\end{remark}

\subsection*{Appendix: Eigenvalues of collapsing domain}

It is important to study the asymptotic behavior of eigenvalues when a domain
collapses. In this appendix, we give some preliminary results in this direction.
\\

We begin with the following observation. Consider the sector
\\% figures 
What is the asymptotic behavior of the Dirichlet eigenvalues when
$\alpha\rightarrow 0$?
\\

As is well-known, the eigenfunctions of the sector are of the form
\[
f(r)\sin\frac{\theta}{\alpha}
\]
where $f(r)$ is the so-called Bessel function
\[
f'' + \frac{1}{r}f' + \frac{1}{r^2}(r^2 - \frac{1}{\alpha^2})f = -\lambda f
\]
If we set
\[
g(r) = \sqrt{r} f(r)
\]
Then the corresponding equation becomes
\[
-g''(r) + \frac{1}{r^2}(\frac{1}{\alpha^2}-\frac{1}{4})g = \lambda g
\]
When $\alpha\rightarrow 0$, we take the following renomorization:
% renormalization ??
set $1 - r = \alpha^{2/3}x$. Then we have
\[
\frac{1}{r^2} - 1 \sim 2x\alpha^{2/3}
\]
Let $\lambda = \widetilde\lambda + \frac{1}{\alpha^2}$. Then we have
\[
-g''(r) + \left(\frac{1}{r^2}\left(\frac{1}{\alpha^2}-\frac{1}{4}\right)-
\frac{1}{\alpha^2}\right)g
= \widetilde\lambda g
\]
and if $\alpha\rightarrow 0$, we have
\[
-g'' + 2xg = \lambda g
\]
This is the Airy's function.
\\

Friedlander and Solomyak was able to generalize the above result in the 
following setting:
\\

Let $h(x) > 0$ be a piecewise linear function defined on $[-a, b]$, where
$a, b > 0$. We assume that
\[
h(x) = \left\{
\begin{array}{ll}
M-C_+x & x > 0 \\
M-C_-x & x < 0
\end{array}
\right.
\]
where the choice of $M, C_+, C_-$ are so that $h(-a) = h(b) = 0$.
\\

For any positive $\varepsilon > 0$, let
\[
\Omega_\varepsilon = \{(x,y)|x\in I, 0\leqslant y \leqslant \varepsilon h(x)\}
\]
\begin{theorem}
[Friedlander-Solomyak] Let $\alpha = 2/3$. Let $l_j(\varepsilon)$ be the
Dirichlet eigenvalues of $\Omega_\varepsilon$. Let
\[
\mu_j = \lim_{\varepsilon\rightarrow 0}
\varepsilon^{2\alpha}
\left(l_j(\varepsilon) - \frac{\pi^2}{M^2\varepsilon^2}\right).
\]
exists. Then $\{\mu_j\}$ are eigenvalues of the Schr\"{o}dinger operator $H$ on
$L^2(\mathbb{R})$, where
\[
H = -\frac{d^2}{dx^2} + q(x)
\]
where
\[
q(x) = \left\{
\begin{array}{ll}
2\pi^2 M^{-3} C_+x & x > 0 \\
2\pi^2 M^{-3} C_-x & x < 0
\end{array}
\right.
\]
\end{theorem}

Note that if $C_+ = C_-$, then $H$ turns to the harmonic oscillator. If
$C_+ = +\infty$, then it turns to the above discussed case.

\begin{theorem}
[Lu-Rowlett] Let $M$ be a triangle and let $d$ be the diameter of $M$. Then
\[
d^2(\lambda_2 - \lambda_1) \rightarrow +\infty
\]
if the triangle collapses. In other words, the ``gap" function is a proper
function on the moduli space of triangles.
\end{theorem}

The original proof of the above result is independent to the work of Friedlander
\textit{et.la.}
\\

\textbf{Question}. Let $h(x) > 0$ be a piecewise smooth function on a bounded
domain $\Omega$ of $\mathbb{R}^n$. Let
\[
\Omega_\varepsilon = \{(x,y)|x\in\Omega, 0\leqslant y\leqslant\varepsilon h(x)\}
\]
Then what is the asymptotical behavior of the Dirichlet (Neumann) eigenvalues of
$\Omega_\varepsilon$.
\\

The question is very important in answering the following conjecture of 
Van den Berg and Yau.
\begin{conjecture}
Let $\Omega$ be a convex bounded domain in $\mathbb{R}^n$. Then
\[
\lambda_2 - \lambda_1 \geqslant \frac{3\pi^2}{d^2}
\]
\end{conjecture}
The conjecture is asymptotically optimal for thin rectangles.
\\

In some sense, the result of Friedlander gives the compactification of the
Laplacians on the moduli space. Namely, if $\alpha\rightarrow 0$, then the
Laplace operators tend to the Schr\"{o}dinger operator defined above.
\\

As an application, we relate the result to the following conjecture.
\begin{conjecture}
Does it exist a number $N$ such that the first $N$ Dirichlet eigenvalues
determine to triangle.
\end{conjecture}

The result of Chang-Deturck gives partial answer to the above conjecture:
\begin{theorem}
There exists $N = N(\lambda_1, \lambda_2)$ such that 
$\lambda_1, \cdots, \lambda_N$ determines the triangle.
\end{theorem}

Unfortunately, if $\alpha\rightarrow 0$, $N = N(\lambda_1,\lambda_2)\rightarrow
+\infty$.
\\

In order to solve this ``hearing the shape of a triangle" problem, we consider
the following parametrization of the moduli space of a triangle when one of the
angle is small
\\% figure
where $b\leqslant 1$, and we use $(\alpha, b)$ as coordinates.
\begin{conjecture}
Let $\xi = \alpha^{2/3}$. Define two functions
\begin{eqnarray}
\nonumber P(\zeta, b) & = & \lambda_2 / \lambda_1 \\
\nonumber Q(\zeta, b) & = & (\lambda_3 - \lambda_2)/(\lambda_2 - \lambda_1)
\end{eqnarray}
Then $P,Q$ are analytic functions on $[0, \varepsilon) \times[\frac{1}{2}, 1]$.
\end{conjecture}

Note that by the result of Friedlander-Solomyak, we know that
\begin{eqnarray}
\nonumber P(\zeta, b) & = & 1 + a\zeta + O(\zeta) \\
\nonumber Q(\zeta, b) & = & 1 + o(1)
\end{eqnarray}

The hearing problem is implied by proving
\[
(\zeta, b) \mapsto (P,Q)
\]
is invertible.
\\

Since the limit of the Laplacian is the $1$-d Schr\"{o}dinger operator, we must
first solve the problem of hearing the Schr\"{o}dinger operator. Gelfand-Levitan
theory doesn't apply directly here.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%