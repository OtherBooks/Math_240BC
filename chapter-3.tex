
\chapter{Gradient estimates}\label{Gradient_estimate}
\section{Comparison Theorems}\label{Comparison_theorems}

Let $X$ be a Riemannian manifold with the Riemannian metric $ds^2$. Let $ \omega_1, \ldots, \omega_n $ be one forms such that 
%
\[ d s^2 = \omega ^2_1 + \cdots + \omega ^2_n. \]
%
Then by the theorem of Cartan, there are one forms $ \{ \omega_{ij} \} $ with $ \omega_{ij} = - \omega _{ji} $, called the connection forms, such that 
%
\[ \left\{ \begin{array}{ll} d \omega_i = - \omega_{ij} \wedge \omega_j \\
d \omega _{ij} = - \omega _{ik} \wedge \omega_{kj} + \frac{1}{2} R_{ij kl} \, \omega _k \wedge \omega _l \end{array} \right. .\]
%
The tensor $R_{ij k l} $ is called the curvature tensor of the Riemannian metric $ d s^2 $.

Let $ U \subset \mathbb{R} ^{n-1} $ be an open set. Let $ \eta _2 , \ldots, \eta _n $ be smooth one forms on $ U$ such that  
%
\[ (ds^1)^2 = \eta ^2_2 + \cdots + \eta ^2_n \]
defines a Riemannian metric on $U$. Let $ \theta _2, \ldots, \theta _n $ be local coordinates of $U$. Let $ f (r, \theta) $ be a positive function on $ \mathbb{R}^+ \times U$. Define a Riemannian metric 
%
\[ ds^2 = d r ^2 + f^2 (r, \theta) \sum ^n _{i=2} \eta ^2 _i \]
on $ \mathbb{R} ^+ \times U$. 



 Example of the above setting appears in the Euclidean metric under polar coordinates. For example, in $ \mathbb{R} ^2$, the Euclidean metric can be written as 
%
\[ d s^2 = d r^2 + r ^2 d \theta^2.\]
For this particular example,
of course, the curvature of the above metric is zero. We shall see that, even in the more general 
setting, certainly components of the curvature tensor appear to be  quite simple.

We let 
\begin{eqnarray*}\omega_1 & = &d r \\
\omega_k & = &f (t , \theta ) \eta_k
\end{eqnarray*}
for $k>1$.
Then 
%
\[ d s^2 = \omega ^2_1 + \cdots +\omega ^2_n .\]
Let $ e_1 , \ldots, e _n $ be the dual basis of $ \omega_1, \ldots, \omega_n $, and let $ \eta_{kl} $ be the connection form for $ (ds^1)^2 $. Define
%
\begin{eqnarray*}
\omega_{1l} & = & - e _1 (\log f) \omega_l;\\
\omega_{kl} & = & \eta _{kl} - e _k (\log f) \omega_l + e _l (\log f) \omega _k\end{eqnarray*}
for $ k , l > 1$. A straightforward computation gives
%
\[ d \omega_i = - \omega_{ij} \wedge \omega_j .\]
%
Note that $ e_1 = \frac{\partial }{\partial r} $. We claim that 
\[ d \omega _{1l} + \omega _{1k} \wedge \omega _{kl} = - \frac{e_k \left( \frac{\partial f}{\partial r} \right)}{f} \omega _k \wedge \omega _l.\]
%
Verification: 
Since
%
\[ \omega _{1l} = - \frac{\partial }{\partial r} (lg f) \omega_l,\]
we have 
\[ d \omega _{1l} = - e _{k}  \left(\frac{\partial }{\partial r}( \log f)  \right) \omega _k \wedge \omega_l - \frac{\partial }{\partial r}( \log f)  d\omega_l . \]
%
On the other hand, we have 
\begin{eqnarray*}
\lefteqn{\omega_{1k} \wedge \omega_{kl} }\\
&& = -\frac{\partial }{\partial r}( \log f)   \omega_k \wedge \left( \eta _{kl} - {e}_k (\log f) \omega_l +    e _l (\log f) \omega _k \right) \\
&  &= \frac{\partial }{\partial r}   d \eta_l +  \frac{\partial }{\partial r}( \log f)     e _k (\log f) \omega_k \wedge \omega_l .
\end{eqnarray*}
%
Since
%
\[ {e} _m \left(\frac{\partial }{\partial r}  \log f\right)    = f^{-1} {e}_m \frac{\partial f}{\partial r}( \log f)    - { e}_m (\log f) \frac{\partial }{\partial r}( \log f),  \]
%
we have 
%
\[ d \omega _{1l} + \omega _{1k} \wedge \omega_{kl} = - \frac{{e}_m \left( \frac{\partial f}{\partial r} \right) }{f} \omega _m \wedge \omega_l.\]
%
The claim is proved. By the Cartan's formula, we have
%
\[R _{1l  m n} = - \delta _{ln}  \frac{{e}_m \left( \frac{\partial f}{\partial r} \right) }{f}  + \delta _{lm} \frac{{e}_n \left( \frac{\partial f}{\partial r} \right) }{f} . \]
%
The Ricci curvature at $ \frac{\partial }{\partial r} $ direction is 
%
\[R_{11} = R_{1 l 1 l} = - (n-1) \frac{1}{f} \frac{\partial ^2 f}{\partial r^2}.\]
%

In general, A Riemannian metric under the polar coordinates can be written as 
 
%
\[ ds^2 = (dr)^2 + h _{ij} (r, \theta) d \theta _i d \theta_j .\]

In order to compute/estimate the curvature, we use  Uhlenbeck's trick which we introduce now.


Let $ \omega _1 = dr$ and $ \omega _2 , \ldots, \omega_n $ be defined such that 
%
\[ h_{ij} d \theta_i d \theta_j = \sum_{j > 1} \omega ^2 _j .\]
%
We write 
\[ \frac{\partial \omega _j}{\partial r} =\sum_{j>1} a_{ij} \omega _j \]
for $i>1$
%
for some matrix valued function $(a_{ij})$. The Uhlenbeck's trick is  that, by an orthogonal change of the co-frame, we can make $(a_{ij})$ a  symmetric matrix.

To see this, we write the above equations into matrix form. Let 
%
\[ \omega = \left( \begin{array}{c} \omega_2 \\
\vdots\\
\omega_n\end{array}\right),\quad   A = (a_{ij}) .\]
%
Then 
\[ \frac{\partial \omega}{\partial r } = A \omega .\]
%
Let $ A = B+C $ be the decomposition of the matrix $A$ into symmetric and skew-symmetric parts.
Let $ Q$ be an orthogonal matrix-valued function. 
We solve the equation

\[ \frac{\partial Q}{\partial r}    = - QC\]
with the initial value $Q(0)=I$. It is not hard to verify that $Q$ are orthogonal matrices: we have
\[ \frac{\partial (Q^TQ)}{\partial r}  = -\frac{\pa Q^T}{\pa r}Q+Q^T\frac{\pa Q}{\pa r}=0\]
using the differential equation and the fact that $C$ is skew-symmetric.

Changing the co-frame from $\omega$ to $Q\omega$, we have
\[
\frac{\pa}{\pa r}(Q\omega)=QBQ^T(Q\omega).
\]
Since $QBQ^T$ is symmetric, up to an orthogonal change of the co-frame, we may assume thst the matrix $A$ is symmetric. This proves the Uhlenbeck's trick.

Now back to the computation of the curvature. Let $(\eta _{ij} )( i , j > 1)$ be the connection forms of the Riemannian metric 
\[ h_{ij} d \theta _i d \theta _j. \]
%
Define 
\begin{eqnarray*}
\omega_{i1} & = & \frac{\partial \omega_i}{\partial r};\\
\omega _{ij } & = & 
\eta_{ij} \end{eqnarray*} 
for $i,j>1$.
Then we have 
\[ d \omega _i = - \sum_{j=1}^n\omega_{ij} \wedge \omega_j\]
for $ i > 1 $.  On the other hand, since $A$ is symmetric, we have
\[
\omega_{i1}\wedge\omega_i=0.
\]
Therefore, $d\omega_1=0=-\omega_{1j}\wedge\omega_j$.
Thus $(\omega_{ij})$ is connection forms of $(ds)^2$ with respect to the co-frame $(\omega_1,\cdots,\omega_n)$. 

We compute
%
\[ d \omega _{i1} + \omega _{ik}  \wedge \omega _{k 1} = \frac{1}{2} R_{il  kl} \omega _k \wedge \omega _l .\]
%
If we only count the terms of the form $ \{ d r \wedge \omega_i \} $  in the above equation, we have

\[
dr\wedge\frac{\pa w_{i1}}{\pa r}=R_{i11j}\omega_1\wedge\omega_j.
\]

Thus we have
\[
{\rm Ric}\,\left(\frac{\pa}{\pa r}, \frac{\pa}{\pa r}\right)=R_{11}=\frac{\pa}{\pa r}\left(\sum_{i>1}a_{ii}\right)
+\sum_{i,j>1}a_{ij}^2.
\]
On the other hand, we have
\[
\frac{\pa}{\pa r}(\omega_1\wedge\cdots\wedge\omega_n)=(\sum_{i>1} a_{ii})\omega_1\wedge\cdots\wedge\omega_n.
\]
Therefore we have
\[
{\partial\over \partial
 r} \sqrt{\det h_{ij}}  =\sum a_{ii}  \sqrt{\det h_{ij}}.
 \]
 
 Using the Cauchy inequality, we have
 \begin{equation}\label{1}
 {\rm Ric} \left( \frac{\partial }{\partial r}, \frac{\partial }{\partial r} \right) \geq\frac{\pa^2}{\pa r^2}\sqrt{\det h_{ij}}+\frac{1}{n-1}\left(\frac{\pa}{\pa r}\sqrt{\det h_{ij}}\right)^2.
 \end{equation}
 
 Using the above computation, we get the following comparison theorem.

\begin{theorem}[Laplacian comparison theorem] Let $X$ be a complete Riemannian manifold of dimension $n$. Let
\[{\rm Ric} (X) \geq - (n - 1) K .\]
%
Let $N$ be an $n$-dimensional simply connected space form of constant sectional curvature $ -K $. Let $ \rho_M, \rho_N $ be the distance functions to fixed reference points, respectively. If $ x \in X $ and $ y \in N $ such that 
%
\[ \rho_M (x) = \rho _N (y) .\]
%
Then in the sense of distribution, we have 
\[ \Delta \rho _M (x) \leq \Delta \rho _N (y). \]
\end{theorem}

\noindent{\bf Proof:} Outside the cut-locus and the reference points, the function $ \rho_M$ is smooth. Since $ \rho_M $ is the distance function,
%
\[ |\nabla \rho_M|=1.\]
%
The Laplacian can be written as 
\[ \Delta_M = \frac{1}{\sqrt{g}} \frac{\partial }{\partial x_i} \left( g^{ij} \sqrt{g} \frac{\partial }{\partial x_j}\right). \]
%
Under the assumption that 
\[ ds^2 = d\rho^2 +\sum_{i,j} h_{ij}\, d \theta_i d \theta_j, \]
%
we have 
%
\[\Delta \rho = \frac{\partial f}{\partial r},\]
where $f=\sqrt{\det h_{ij}}$.
%
By ~\eqref{1}, we have
\[ \frac{\partial^2 f}{\partial r^2} + \left( \frac{\partial f}{\partial r} \right) ^2 \geq - {\rm Ric} \left( \frac{\partial }{\partial r} , \frac{\partial }{\partial r} \right) .\]
%
The corresponding function on $N$ satisfies the {\it equality}
\begin{equation} \label{2}
\frac{\partial^2 f_0}{\partial r^2} + \left( \frac{\partial f_0}{\partial r} \right) ^2 = ( n-1) K.
\end{equation}
%
If $r\to 0$, the asympototics  $f$ and $f_0$ are 
%
\[ \frac{\partial f}{\partial r}  \sim \frac{n-1}{  r} ,  \;\;  \frac{\partial f_0}{\partial r} \sim  \frac{n-1}{\partial r}.  \]
Since
%
\[ - {\rm Ric} \left(    \frac{\partial }{\partial r} ,  \frac{\partial }{\partial r}  \right) \leq ( n - 1) K,\]
%
By the maximum principle 
%
\[ \frac{\partial f}{\partial r}  \leq \frac{\partial f_0}{\partial r_0}.  \]
%
This proves the comparison theorem at the smooth points of $f$.


Solving the equation~\eqref{2}, we get 
%
\[ f_0(r) = \frac{1}{\cosh \,  \sqrt K} \cdot \sinh \, \sqrt K r .\]
%
Thus we have 
%
\[ \Delta _N \rho = \frac{n-1}{\rho} k \rho \coth k\rho \leq \frac{n-1}{\rho}  (1 + k \rho). \]
 %
Thus the Laplacian comparison theorem can be written in the following more useful form:
%
\[ \Delta _M \rho \leq \frac{n-1}{\rho} ( 1 + k \rho) .\]

We shall prove that the above inequality is true even at singular points of $ \rho$, in the sense of distribution. To see this, we let $ \Omega $ be the domain in $X$ such that $\rho$ is smooth on $ \Omega$. $ \Omega$ is a star-like domain in $X$. Apparently
%
\[ X = \Omega \cup C u t (p) \]
%
where $ Cut(p)$ is the cut-locus of $X$. Since $ \rho $ is at least continuous, and since the measure of $ Cut (p) $ is zero, we must have 
%
\[ \int _X \rho \Delta \varphi = \int _{\Omega}  \rho \Delta \varphi \]
%
for any smooth function $ \varphi$.  Let $ \Omega _\varepsilon $ be an exhaustion of $ \Omega $  in the sense that $ \Omega _\varepsilon  \subset \Omega $. $ \Omega _\varepsilon \subset \Omega  _{\varepsilon^{\prime}} $ if $ \varepsilon > \varepsilon ^\prime $, and 
%
\[ \lim_{\varepsilon \rightarrow 0} \Omega _\varepsilon = \Omega. \]
Then we have 
\begin{eqnarray*}
\int_X \rho \Delta \varphi & = & - \int_X \nabla \rho \nabla \rho \\
& = & \lim _{\varepsilon \rightarrow 0} (-1) \int _{ \Omega \varepsilon} \nabla \rho \nabla \varphi .
\end{eqnarray*}
%
Using the Green's formula, we have 
%
\[ - \int _\Omega \nabla \rho \nabla \varphi = \int _ \Omega \nabla u \cdot \varphi - \int _{\partial \Omega \varepsilon } \varphi \frac{\partial \rho}{\partial r} .\]
%
On the boundary $ \partial \Omega \varepsilon$, we have 
%
\[ \frac{\partial \rho}{\partial r} \geq 0 .\]
%
Thus we have 
\[ - \int _\Omega \nabla \rho \nabla \varphi \leq \int _ {\Omega \varepsilon} \Delta  \rho \cdot \varphi \leq   \int _{\Omega \varepsilon } \frac{n-1}{\rho }  ( 1+k\rho)\varphi 
\]
%
Finally, we get 
%
\begin{eqnarray*}
\int_X \rho \nabla \varphi  & \leq & \lim_{\varepsilon \rightarrow 0} \int _{\Omega \varepsilon} \frac{n-1}{\rho} ( 1 + k \rho) \varphi \\
& = & \int_X \frac{n-1}{\rho}(1+ k \rho) \varphi 
\end{eqnarray*}
which finishes the proof of the theorem.
\qed 


Using exactly the same method, we have the following volume comparison theorem of Bishop.

\begin{theorem}Let $X$ be an $n$-dimensional complete Riemannian manifold.  Let 
%
\[ {\rm Ric}(X) \geq - (n-1) k^2 .\]
%
Then
%
\[ \frac{{\rm vol} \, \partial B(R)}{{\rm vol} _k \,( \partial B (R))} \downarrow\]
%
is a decreasing function.
\end{theorem}


\begin{corollary}[Bishop] Let $ X$ be an $n$-dimensional Riemannian manifold. If $ {\rm Ric} \geq (n-1) k$. Then for any 
$R > 0 $ 
\end{corollary}
%
\[\frac{{\rm vol}\, (B_X (R))}{{\rm vol} (k, R)} \]
%
is a decreasing function. In particular 
%
\[ {\rm vol} B_X (R) \leq V (k, R) \]
%
where $ V(k, R) $ is the volume of ball of radius $R$ in space form of curvature $k$.


\begin{remark} The Bochner formula gives another proof of ~\eqref{1}. Let $f$ be a smooth function. Then we have
%
\[\frac{1}{2} \Delta |\nabla f| ^2 = |\nabla ^2 f |^2 + \frac{\partial }{\partial r} \Delta f + {\rm Ric} ( \nabla  f, \nabla f ).\]
%
If we specialize $f$ to be $r$, then $ |\nabla r |^2 = 1 $ and $ \Delta |\nabla r| ^2 \equiv 0$.  On the other hand
%
\[| \nabla ^2 f |^2 \geq \sum_i f_{ii}^2 \geq \frac{1}{n-1} \left( \sum f_{ii} \right) ^2 = \frac{1}{n-1} ( \Delta f ) ^2,  \]
%
and the inequality follows. 
\end{remark}

\begin{remark} The proof of the laplacian comparison theorem in this section is not that far away from the usual proof using the second variational formula of the geodesic distance. The fact that we can write the Riemannian metric in the form

\[dr^2 + h_{ij} d \theta_i d \theta_j \]
is ensured  by the Gauss Lemma,  which is proved by the first variational formula of the geodesic distance function.
\end{remark}



\section{Gradient estimates and maximal principle}\label{Maximal_principle}

If $X$ is a compact manifold, then any smooth real function on $X$ reaches its maximum point. At the maximum point, the first derivatives are zero, and the Hessian matrix at the point is non-positive.

For non-compact manifold, the above statement is not true in general. In order to estimate a function we sometimes need a differential inequality. Usually such a differential inequality is obtained by doing the so-called gradient estimate.

We start with the following generalized maximum principle:

\begin{theorem} Let $ f$ be a positive smooth function on a complex non-compact Riemannian manifold $X$. We assume that $ {\rm Ric} (X) \geq - (n-1) k^2 $ for some number $k$. Let $ \varphi_1, \varphi_2 $ be two smooth functions on $X$ with $ \varphi_1 $ bounded. Assume that there are constants $ \alpha > 0 , C_1, C_2 $ such that
\end{theorem}
\begin{equation} \nabla f \geq C_1 f ^{l+ \alpha} + \varphi _0 \nabla \varphi_1 \nabla f - C_2 .\tag*{$\star$} \end{equation}
%
Then $f$ is bounded. Furthermore, there is a constant 
\[
C = C (\alpha, C_1, C_2 \Vert \varphi _0 \Vert C_0 \nabla \varphi _1 ) 
\]
 such that 
%
\[ f \leq C.\]

\noindent{\bf Proof:}
We first assume that $ f$ is bounded. That is 
%
\[ \sup f < + \infty.\]
We claim that there is a sequence $ \{ x_k\} $ in $X$ such that for any $ \varepsilon > 0 $, if $ k$ is large enough, we have 
\begin{eqnarray*}
&&f(x_k) > \sup f - \varepsilon \\
&& | \nabla f | (x_k) < \varepsilon \\
&&\Delta f (x_k) < \varepsilon.
\end{eqnarray*}

To prove the claim, we first take a sequence $ \{ y_k\} $ such that 
%
\[ \lim_{k \rightarrow \infty}  f (y_k) = \sup f.\]
%
Define the cut-off function $ \rho $ as follows 
%
\[ \varphi : \mathbb{R} \rightarrow \mathbb{R}\]
%
smooth, $ 0 \leq \rho \leq 1, \rho (t) = 1 $ for 	 $ 0 \leq t \leq 1$. $ \rho (t) = 0 $ for $ t > 2 $ and $ \rho^\prime (t) \leq 0$ for all $ t \in \mathbb{R} $. Let $R$ be a large number to be determined later. 
Let $d(x) = {\rm dist}  (x, y_k) $ be the distance function. In general, the function $ d(x) $ is only a continuous function. But let 
%
\[ g(x) = \rho \left( \frac{d^2(x)}{R^2} \right) f (x) .\]


If the maximum point of $g(x) $ happens to be not smooth, we can always perturb the reference point by a little. So without loss of generality, we assume that $g(x) $ is smooth. Let $ x_k$ be the maximum point of $ g(x)$. By the definition of $ x_k$, we have 
%
\[g(x_k) \geq g (y_k) = f (y_k) \geq \sup f - \varepsilon. \]
%
Using the definition, we also have 
%
\[1 - \rho \left( \frac{d^2 (x_k) }{R^2} \right) \ < \frac{\varepsilon }{\sup f }.\]
%
Since 
%
\[ 0 = \nabla g (x_k) = \rho^\prime \frac{2}{k^2} d \nabla d f (x_k) + \rho \nabla f (x_k)\]
we have 
% 
\[ |\nabla f| (x_k)= - \frac{\rho^\prime}{\rho} \frac{2}{k^2} d | \nabla d |f (x_k).\]
%
Because $ | \nabla d | = 1$, if $R$ is big enough, we have 
%
\[ |\nabla f| (x_k) < \varepsilon. \]
%
Finally, we have 
%
\[ 0 \geq \Delta g (x_k) = \rho f + 2 \nabla \rho \nabla f + f \Delta \rho.\]
%
In order to prove the claim, we just need to prove that 
%
\[ \Delta \rho \left( \frac{d^2 (x, y_k )}{R^2} \right) < \varepsilon \]
for $k$ large enough. A straight forward computation gives that 
%
\[ \Delta \rho = \frac{2}{R^2} \rho^\prime + \frac{4d^2}{R^4} \rho^{\prime \prime} + \frac{2}{R^2} \rho^\prime d \Delta d .\]
%
Since the Ricci curvature of $X$ is bounded from below, by Laplacian comparison theorem, we have 
%
\[d \Delta d \geq -C\]
%
for some constant $C$ depending only on the lower bound of the Ricci curvature. Since $ \rho^\prime  \leq 0$, for $R$ large enough we have 
%
\[ \Delta \rho < \varepsilon \]
%
for any $ \varepsilon$. The claim is proved.

Using the differentiable inequality ($\star$), we have 
%
\[ \varepsilon \geq C_1 f (x_k) ^{1 + \alpha} = \Vert \varphi_0 \Vert \, \Vert \nabla \varphi_1 \Vert \varepsilon - C_2 .\]
%
Thus 
%
\[ f (x_k) \leq {}^{1+\alpha}\sqrt{\frac{C_2 + \Vert\varphi _0\Vert \,\Vert  \nabla \varphi _1 \Vert}{C_1}} \ .\]
%
Taking $ k \rightarrow \infty$, we get the effective bound for $f$. 

Now we assume that $ \sup f =   + \infty$. Let 
%
\[ v = 1 - \frac{1}{(1+f) ^\beta} \]
%
for $ \beta > 0 $ to be determined later. Then by the previous result, there is a sequence $ \{ x_k\} $ such that for any $ \varepsilon > 0 $, if $k$ is large enough, we have
%
\begin{eqnarray*}
&&v (x_k) > 1 - \varepsilon\\
&& |\nabla v | (x_k) < \varepsilon \\
&& \Delta v (x_k) < \varepsilon .
\end{eqnarray*}
%
By the definition of $v$, we have 
%
\[ \Delta  v = \beta \frac{\Delta f }{(1+ \delta )^{1+ \beta}} - \frac{1+\beta}{\beta} | \nabla v|^2 (1 +f )^\beta \]
%
Applying the above inequality to  $(\star)$, we get 
%
\[ \varepsilon > \beta \frac{C_1 f^{1+\alpha}- \Vert\varphi _0\Vert \,\Vert \nabla \varphi _1 \Vert \cdot \varepsilon - C_2}{(1+f ) ^{1 + \beta}} - \frac{1+\beta }{\beta} \cdot \varepsilon (1 + f)^\beta .\]
%
Letting $ k \rightarrow \infty$, we get a uniform bound of $\sup f $ from the above inequality.

Let $f$ be a smooth function on a complete non-compact manifold. We say that $f$ is a harmonic function, if 
%
\[ \Delta f = 0 .\]
Then we have the following:

\begin{theorem}[Yau] Let $ p > 1 $, if $ f \in L ^p , \Delta f = 0 $. Then $ f $ is a constant.
\end{theorem}
For the sake of simplicity, we only prove the theorem for $p = 2$.

Let $ f$ be an $ L^2 $ harmonic function. Take a fixed point $ x_0$. Let
%
\[ d (x) = {\rm dist} (x, x_0).\]
%
Let $ \rho $ be a cut-off function such that $ {\rm supp} \rho $ is compact. We consider 
%
\[ g (x) = \rho \left( \frac{d(x)}{R} \right) f (x) .\]
%
We have 
%
\[ \int_M \rho ^2 | \nabla f (x) |^2 = - 2 \int \rho f \nabla \rho \nabla f \frac{1}{R}.\]
%
Using the Cauchy inequality, we get 
%
\[ \int_M \rho^2 | \nabla f | ^2 \leq \frac{2}{R} \left( \int_M \rho^2 |\nabla f|^2 \right) ^{\frac{1}{2}} \int_M |\nabla \rho| ^2 f .\]
%
Since $ | \nabla \rho | \leq C$. We get 
%
\[ \int_M \rho^2 |\nabla f | ^2 \leq C \frac{1}{R} \int_M f^2.\]
%
Letting $R\rightarrow \infty $, we get $ \nabla f  \equiv 0 $ so $f$ is a constant.

By the above theorem, for a complete manifold, the only interesting harmonic functions may be bounded harmonic functions.

In order to study the bounded harmonic functions, we first introduce the Ricci identity.

Let $ f$ be a smooth function of $M$. Define the derivative of $f$ using the following formula 
%
\[ f_i \omega _i = df. \]
%
Using the same idea, we define 
%
\[ f_{ij} \omega _j = d f_i - f _s \omega _{s j} .\]
%
The matrix $ (f_{ij} )$ is called the Hessian matrix. We have 
%
\[ f_{ij} \omega _j \wedge \omega _i = d f _i \wedge \omega _i - f _s \omega _{s j} \wedge \omega _i = 0 .\]
%
Thus the Hessian matrix is always symmetric.

The 3$^{\rm rd}$ order co-variant derivatives are defined as 
%
\[ f_{ijk} \omega _k = d f _{ij} - f _{is} \wedge \omega  _{sj} - f  _{sj} \wedge \omega _{si} .\]
%
A careful computation gives 
%
\[f_{ijk} \omega _k   \wedge \omega  _{j}= - \frac{1}{2}f_s   R_{si kj}   \omega _k \wedge \omega _j.\]
%
Thus we have
%
\[ f_{ijk} - f _{ikj} = + f _s R_{sikk} \]
In particular, we have the following Ricci identity
%
\[f_{iik} - f _{kii} = - f_s {\rm Ric} _{sk}\]

\begin{remark}
We have $ \Delta f = f _{ii} $.
\end{remark}

With the preparation above, we prove the following.

\begin{theorem} Let $ M$ be a complete Riemannian manifold, $ \dim M = n \geq 2$. $ {\rm Ric}(M) \geq - (n-1) k , k \geq 0 $. Let  $u$ be a positive harmonic function. Then on any geodesic ball $ B_a (x) $, we have 
\end{theorem}
\[ \frac{|\nabla u|}{u}  \leq C_n \left( \frac{1+ a k ^{\frac{1}{2}}}{a} \right) .\]
%
where $C_n $ is a constant only depends on $n$.
We first prove that 
%
\begin{equation} \frac{1}{2} \Delta |\nabla u | ^2 \geq \sum _{ij} u_{ij} ^2 - (n-1) k | \nabla u|^2. \tag{$\triangle$}\end{equation}
To see this, we do the following
%
\[ \left( \sum u^2_j\right) _i = 2 u_j u_{ji}. \]
Thus,
%
\[ \frac{1}{2} \Delta |\nabla u | ^2 + ( u_j u_{ji} )_i = u ^2_{ji} + u_j u_{jii}. \]
Using the Ricci identity, we have 
%
\[ \frac{1}{2} \Delta |\nabla u| ^2 = u^2_{ji} + u _j (\Delta u)_j + {\rm Ric} (\nabla u, \nabla u) .\]
%
Thus  $ (\triangle) $ follows from the assumption on the Ricci curvature and harmonicity of $u$.

We now consider the points such that $ \nabla u \neq 0$. By changing a frame, we may assume that 
%
\[ u_i \neq 0 , \ u_j = 0 \ \mbox{for}\ \ j < 1 .\]
%
From $ (\triangle)$, we conclude that 
%
\[ \Delta | \nabla u| = \frac{\Delta | \nabla u|^2}{2 | \nabla u|} - \frac{1}{4} \frac{| \nabla | \nabla u| ^2 |^2}{| \nabla u|^3}. \]
%
Using the above information, we get 
%
\[ \Delta |\nabla u| \geq \frac{1}{| \nabla u|} \left( \sum_{j > 1} u^2_{ij} + \sum _{j>1} u^2_{jj} \right) - (n-1) k |u_1|.\]
%
Since 
%
\[ \sum _{j>1} u^2_{jj} \geq \frac{1}{n-1} \left( \sum_{j>1} u_{jj} \right) ^2 = \frac{1}{n-1} u^2_{11}.\]
%
we have 
%
\[ \Delta |\nabla u| \geq \frac{1}{n-1} \frac{1}{|\nabla u|} \sum_j u^2_{ij} - (n-1) k |u_1|.\]
%
Now we assume that $ \varphi = |\nabla u|/u$. Then we have 
%
\[ \Delta \varphi = \frac{\Delta |\nabla u|}{u} + 2 \nabla |\nabla u| \nabla \frac{1}{u} + |\nabla u| \Delta \left( \frac{1}{u} \right). \]
%
Since
\[ 2   \nabla  | \nabla u| \nabla \frac{1}{u} =  2 \nabla (\varphi u) \nabla   \left(\frac{1}{u} \right) = - 2 \frac{\nabla \varphi \nabla u}{u} - 2 \varphi ^3 .\]
%
We have 
%
\[ \nabla \varphi = \frac{\Delta |\nabla u|}{u} - 2 \frac{\nabla \varphi \nabla u}{u} .\]
%
We have 
\[\frac{\nabla \varphi \nabla u}{u} = - \varphi ^3 - 2 \nabla |\nabla u| \nabla \frac{1}{u}.
\]
Thus if $ \varepsilon > 0 $ is small enough
%
\[  \frac{\Delta |\nabla u|}{u} - \varepsilon \frac{\nabla \varphi \nabla u}{u} \geq \varepsilon \varphi ^3.\]
%
Thus we get 
%
\[ \Delta \varphi \geq - (n-1) k \varphi - (2 - \varepsilon ) \frac{\nabla \varphi \nabla u}{u} + \varepsilon \varphi^3 .\]
%
Using the maximum principle, we have $ \varphi $ is bounded.

\begin{corollary} Let $ M$ be a complete Riemannian manifold, if ${\rm Ric} (M) \geq 0 $. Then any positive harmonic function is a constant.
\end{corollary}

\noindent{\bf Proof:} If ${\rm Ric} \geq 0 $ then $k = 0 $. We have 
%
\[ \Delta \varphi \geq - (2 - \varepsilon ) \frac{\nabla \varphi \nabla u}{u} + \varepsilon \varphi^3. \]
%
For $ \varepsilon = \frac{2}{n-1} $. Thus using the generalized maximal principal, $ \varphi \equiv 0 $.
\qed

\begin{corollary}[Harnack **] Let $M$ be $n$-dimensional Riemannian manifold, 
$ {\rm Ric} (M) \geq - (n-1) k $.  If $ u$ is a positive harmonic function in $Ba$. Then 
%
\[ \sup_{Ba/2} u \leq C (n, a, k) \inf_{B a/2}  u\]
%
where $ C (n, a, k)$ are constants depending only on $ n, a, k$.
\end{corollary}

\noindent{\bf Proof:}
By the above theorem, we have 
\[ \sup_{Ba} \frac{|\nabla  u|}{u} \leq C (n, a, k).\]
%
Thus
%
\[ | \nabla lg u |\leq C (n, a, k) \]
%
the conclusion follows.

\begin{corollary} Suppose $ {\rm Ric} (M) \geq 0 $. Then any positive harmonic function must be constant.
\end{corollary}

Let the Riemann metric be written as 
%
\[(dr)^2 + h_{ij} (r, \theta) \, d \theta _i d \theta _j .\]
%
What is the asymptotic behavior of $ h_{ij} (r, \theta) $ when $ r \rightarrow 0$.

Note that the Riemannian metric at the reference point is regular. Thus we can define $ ( \theta _2, \ldots, \theta _n) $ as 
%
\[ \theta _j = \frac{x_j}{r}, \;\; r = \sqrt{\sum x^2_j} .\]
%
Suppose 
%
\[ ds ^2 = g_{ij} d x_i dx_j .\]
%
Let's compare 
%
\[ g_{ij} d x_i dx_j \sim (dr ) ^2 + h_{ij} d \theta _i d \theta _j. \]
%
We have 
\begin{eqnarray*}
g_{ij} d x _i dx_j    & = & g_{ij} ( dr \theta _i + r d \theta _i ) ( d r \theta _j + r d \theta _j ) \\
& = & g _{ij} \theta_i \theta_j (dr) ^2 + 2 g _{ij} x_i dr d \theta _j + g _{ij} r ^2 d \theta _i d \theta _j .
\end{eqnarray*}
%
By comparison, we have 
\begin{eqnarray*} 
&&g_{ij} \theta_i \theta _j = 1 \\
&& \sum _i g_{ij} x _i = 0 \end{eqnarray*}
%
and
%
\[ h_{ij} = r^2 \left(g_{ij} - g_{ij} \frac{\theta_i}{\theta_1} - g_{i1} \frac{\theta_j}{\theta_1} + g_{11} \frac{\theta_i \theta_j}{\theta^2_1} \right).\]
%
Thus 
%
\[ \sqrt{{\rm det} ( h _{ij} ) }
= \gamma ^{n-1} \cdot \mu \]
%
for $ \mu $ being a regular function (at least for fixed $ \theta_i$).
%
Thus
\[ \Delta \rho = \frac{\partial f}{\partial r} \sim \frac{n-1}{r} + \ \mbox{small terms}.\]

If we choose $ (g_{ij}) $ to be normal, we can actually compute 
%
\[ {\rm det}\left( \delta_{ij} + \frac{\theta_i \theta_j}{\theta^2_1} \right) = \frac{1}{\theta^2_1}.\]
%
Thus 
%
\[ \sqrt{{\rm det}\,h_{ij}} \]
can be extended as a regular function near 0.


\section{Harmonic functions revisited}\label{Harmonic_functions}
We assume that $ u$ is a positive harmonic function defined on $ B(a) \subset M $, where $ M$ is a complete Riemannian manifold with ${\rm Ric} (M) \geq - (n-1) k $.

In this section, we re-prove the Harnack inequality using the de Giorgi-Nash-Moser estimates. Note that our {\bf result is weaker} than the differential Li-Yau Harnark inequality. However, the methods we use here are useful in non-linear case, even if we only  use a linear problem as the example.

The reference book of this section is 

***

We first prove the following estimate.

\begin{theorem} Under the above assumptions, then for any $ p > 0 , 0 < \theta < 1 $, there is a constant 
%
\[ C= C (n, p, \theta, k ) > 0 \]
%
 such that 
%
\[ \sup_{B(a\theta)} u \leq C (f _{B(a)} u^p ) ^{\frac{1}{p}}.\]
\end{theorem}

\noindent{\bf Proof:} We first assume that $ p \geq 2$.
Let $ \varphi \geq 0 , \varphi \in C^\infty_0 (B(a))$. Then since  $ \Delta u = 0 $, we have 
%
\[ \int _{B(a)} \nabla u \nabla \varphi = 0. \]
%
Let $\rho$ be a smooth function with compact support in $ B(a)$. Then we have 
%
\[ \int _{B(a)} \nabla u \nabla (\rho^2 u ^{p-1} )  = 0.\]
%
Here $p$ is a real number to be specialized later.

Expanding the above inequality, we get 
%
\[(p-1) \int _{B(a)} \rho^2 u  ^{p -2} | \nabla u|^2 \leq  - 2 \int _{B(a)}  u  ^{p-1} \rho \nabla u \nabla \rho .\]
%
Using the Cauchy inequality, we get 
%
\[(p-1)^2 \int _{B(a)} \rho^2 u  ^{p -2}  | \nabla u|^2 \leq     C \int _{B(a)} |\nabla \rho | u^p.\]
%
Note that 
%
\[  u  ^{p-2}   | \nabla u|^2 = \frac{4}{p^2}   \left|\nabla u  ^{\frac{p}{2}} \right|^2\]
%
we have 
%
\[ 
\left. \int _{B(a)} \rho^2     | \nabla u  ^{\frac{p}{2}} \right|^2   \leq  C   \int _{B(a)}  | \nabla \rho| ^2 u^p \]
%
if we allow $C$ to be a little bigger, we shall get 
%
\[ \left.\int _{B(a)}     | \nabla (\rho u ^{\frac{p}{2}} )\right|^2   \leq  C   \int _{B(a)}  | \nabla \rho| ^2 u^p .\]
%
 We let $ 2^\ast = \frac{2n}{n-2} > 2$. Using the Sobolev inequality we have 
%
\begin{equation} \left(\int _{B(a)}( \rho u    ^{\frac{p}{2}})  ^{2^{\ast}}  \right)   ^{\frac{1}{2^{\ast}}}\leq  C   \int _{B(a)}  | \nabla \zeta |^2 u^p . \tag{$\star$}\end{equation}
%
We let 
%
\[R_k = a \left(\theta + \frac{1-\theta}{2^k}\right). \] 
%
Let $ \rho_k \in C^\infty_0 (B (R_k)) , 0 \leq \rho _k \leq 1, \rho _k \equiv 1 $ on $ B(R_{k+1} )$. We further assume that 
%
\[| \nabla \rho_k| \leq \frac{2}{R_k - R_{k+1}} = \frac{2^{k+1}}{(1-\theta)a}. \]
%
From ($\star$), we have 
\[ \left( \int_{B(R_{k+1})} U ^{\frac{np}{n-p}}\right)^{\frac{n-2}{n}} \leq \frac{C \cdot 4^k}{(1 - \theta )^2 a^2} \int _{B(R_k)} u^p.  \]
%
Specializing $ p = p_k $, where $ p_k = p \left( \frac{n}{n-2} \right) ^k $, we have 
%
\begin{eqnarray*}
&&\Vert u \Vert _{L^{p_{k+1}} (B (R _{k+1} ))} \leq \left ( \frac{C \cdot 4^k}{(1 - \theta )^2 a^2} \right) ^{\frac{1}{p_k}}\\
&& \quad \quad \times  \Vert u \Vert _{L^{p} (B (R _k ))}.
\end{eqnarray*}
Iterating, we have 
%
\[\Vert u \Vert_{L^{p_{k+1}} (B (R _{k+1} ))} \leq \Pi \left ( \frac{C \cdot 4^k}{(1 - \theta )^2 a^2} \right) ^{\frac{1}{p_k}} \Vert u \Vert _{L^{p} (B (a))}.\]
%
We need to prove that 
\begin{equation}\Pi \left ( \frac{C \cdot 4^k}{(1 - \theta )^2 a^2} \right) ^{\frac{1}{p_k}} \leq 
  \frac{C  }{((1 - \theta )^2 a^2)^{\frac{n}{2p}}}   \tag{{\rm Exercises}}\end{equation}
%
Since the right-hand side is independent of $k$, we let $ k \rightarrow \infty $ and get 
%
\[\Vert u \Vert _{L^{\infty} (B (\theta a  ))} \leq  \frac{C  }{((1 - \theta ) a) ^{\frac{n}{p}}}   \Vert u \Vert _{L^{p} (B (a))}.\]
%
This proves the theorem for $ p \geq 2$. 

Now we assume that $ 0 < p < 2$. Using the result for $ p = 2$, we have 
\begin{eqnarray*}\Vert u \Vert _{L^{p_\infty} (B (\theta a  ))} &\leq &     \frac{C }{((1 - \theta ) a)^{\frac{n}{2}}} \Vert u \Vert _{L^{\infty} (B (a))^{1 - \frac{p}{2}}} \\
& \times &  \left( \int _{B(a)} u ^p \right) ^{\frac{1}{2}}.
\end{eqnarray*}
%
Using the Young inequality, we get 
%
\begin{eqnarray*}
\lefteqn{\Vert u \Vert _{L^{\infty} (B (\theta a  ))} \leq     \frac{1 }{2} \Vert u \Vert _{L^{p} (B (a))}}\\
&& + \frac{C }{((1 - \theta ) a)^{\frac{n}{2}}}  \Vert u \Vert _{L^{p} (B (a))}.
\end{eqnarray*}
%
Let $ \varphi (s) = \Vert u \Vert_{L^{\infty} (B (a))} $, we get 
%
\[ \varphi (s) \leq \frac{1}{2} \varphi (t) + \frac{C}{(t-s)^{\frac{n}{p}}} \Vert u \Vert _{L^{p} (B (a))}\]
%
$\forall \  0 < s < t \leq a $. Iterating again, we get 
%
\begin{equation} \varphi (s) \leq   \frac{C}{(1-s)a)^{\frac{n}{p}}} \Vert u \Vert _{L^{p} (B (a))} \tag{{\rm Ex}}\end{equation}
%
\begin{theorem}[Weak Harnack inequality] There is a constant $ C > 0 , p_0 > 0 $ such that
%
\[\inf_{B(a \theta)} u \geq \frac{1}{C} \left( f _{B(a)} u ^{p_{0}} \right) ^{\frac{1}{p_{0}}}.\]
%
Here $p_0, C $ only depends on $ a, (1 - \theta )^{-1} $ and Sobolev constants.
\end{theorem}

\noindent{\bf Proof.}
Without loss of generality, we assume that $ u \geq \varepsilon > 0 $. Otherwise we can use  $u + \varepsilon $ in place of $ u$. We also assume that $ a = 1$. By a straight forward computation we get that 
%
\[\Delta u^{-1} = \frac{2|\nabla u|^2}{u^3} \geq 0.\]
%
Thus $ u^{-1} $ is a subsolution. Using the above lemma, for any $p$, we have 
%
\[\sup _{B(\theta)} u^{-p} \leq C \int_{B(1)} u ^{-p} .\]
%
Thus we must have 
%
\begin{eqnarray*}
\inf _{B(\theta)}u & \geq & C ^{-\frac{1}{p}} \left( \int_{B_{1}} u^{-p} d x \right) ^{-\frac{1}{p}} \\
& = &C ^{-\frac{1}{p}} \left[\int_{B_{1}} u^{-p} \cdot \int_{B_{1}} u^{p} \right] ^{\frac{1}{p}} \\
&    \times& \left( \int_{B_{1}} u^{p} \right) ^{\frac{1}{p}} .\end{eqnarray*}
%
In order to prove the theorem, we just need to prove that for $ p > 0 $ small enough
%
\[ \int_{B(1)} u^{-p} \int _{B_1} u^p \leq C. \]
%
We let
%
\[ \omega = \log u - \beta \]
%
where
%
\[\beta = f \log u. \]
%
We shall establish
%
\begin{equation}\int_{B(1) } e ^{p |\omega |}\leq C  \tag{$\star$} \end{equation}
%
for $ p > 0 $ small enough. We first prove that 
%
\[ \int_{B(\sigma)} | \nabla \omega |^2 \leq C \]
%
for some $ \sigma > 1 $. To see this, let $ \rho $ be the cut-off function whose support is within $ B(\bar{\sigma})$ for some $ \bar{\sigma} > \sigma $. Since $ u$ is harmonic, we have 
%
\[ \int _{B(\bar{\sigma})} \nabla u \nabla ( u^{-1} \rho ^2) = 0. \]
%
It follows that 
%
\begin{eqnarray*}
\int_{B(\bar{\sigma})} \rho^2 |\nabla \omega |^2 & \leq & \int_{B(\bar{\sigma})} \nabla \omega \nabla \rho^2\\
&  \leq&2 \sqrt{\int_{B(\bar{\sigma})}\rho^2 |\nabla \omega |^2  }\sqrt{\int_{B(\bar{\sigma})}  |\nabla \rho |^2} .
\end{eqnarray*}
%
Since $\rho$ only depends on $ \sigma , \bar{\sigma}$, we get the desired inequality.

By the Poincar\'{e} inequality, we have
%
\[ \int_{B(\bar{\sigma})} | \omega |^2 \leq C .\]
%
To get the estimate $(\star)$, we still use the Moser iteration. First observe that 
%
\[ \Delta \omega = - | \nabla \omega |^2.\]
%
Let $ \rho $ be a cut-off function to be determined later. Then we have
%
\[ - \rho ^2 |\omega |^{2 q} \Delta \omega = \rho^2 | \omega |^{2q} | \nabla \omega |^2 .\]
%
It follows that 
%
\begin{eqnarray*}
\int \rho^2 |\omega |^{2q} |\nabla \omega | ^2 & = & \int \nabla \omega \nabla ( \rho^2 |\omega |^{2q})\\
& = & 2 \int \rho \nabla \rho \omega |\omega |^{2q} + 2 q \int \rho^2 |\omega | ^{2q-1} |\nabla \omega |^2. \end{eqnarray*}
%
We use the Young inequality to get  
%
\begin{equation} 2q |\omega |^{2q-1} \leq \frac{2q-1}{2q} |\omega | ^{2q} + ( 2q) ^{2q-1} .\tag{$\triangle$}\end{equation}
%
Inserting the above inequality into the equation, we get 
%
\begin{eqnarray*}
\int \rho ^2 |\omega |^{2q} |\nabla \omega |^2 & \leq & (2q)^{2q} + 2 \sqrt{\int \rho^2 |\omega |^{2q} | \nabla \omega |^2}\\
& \times & \sqrt{\int   |\nabla \rho |^{2} | \omega  |^{2q} }.
\end{eqnarray*}
Using the Cauchy inequality $ ab \leq \varepsilon a^2 + \frac{1}{\varepsilon} b^2$, we get 
%
\[ \int \rho^2 |\omega |^{2q} |\nabla \omega |^2 \leq C (( 2g) ^{2q} + \int |\omega | ^{2q} | \nabla \rho |^2) .\]
%
With a slightly larger constant $C$, we have 
%
\[ \int \rho^2 |\nabla | \omega | ^{q+1} |^2  \leq C  q^2 (( 2q)^{2q} + \int |\omega | ^{2q} | \nabla \rho |^2).\]
%
Thus we have 
%
\[ \int (\nabla ( \rho^2 |\omega |^{q+1}) |^2 \leq 2 C q^2((2q) ^{2q} + \int |\omega | ^{2q+2} | \nabla \rho |^2) .\]
%
Thus replacing $ q + 1 $ by $q$ and choosing the suitable cut-off function, we get 
%
\[\left( \int _{B(\bar{\sigma})} |\omega |  {2^{qk}} \right) ^{\frac{1}{k}} \leq C \left(( 2q) ^{2q} + \tau ^{-2} q ^2 \int _{B(q + \tau)} |\omega | ^{2q}\right).\]
%
Let $ \kappa = \frac{n}{n-1}, \; q_i = \kappa ^{i-1} , \; \delta_0  = \bar{\sigma} > 1$.
%
\[ \delta _i = \delta _{i-1} - \frac{\bar{\sigma} - 1}{2^i}.\]
Then we have
%
\begin{eqnarray*}
\left( \int_{B(\delta i)} | \omega |^{2 +1}\right) ^{\frac{1}{k}}&\leq & C \kappa ^{2(i-1)} \kappa^{i-1}\\
&+ & C (4 k )^i \int _{B (\delta _{i-1})} |\omega |^{2\kappa ^{i-1}}
\end{eqnarray*}
%
We let 
%
\[ I_j = \left( \int _{B\partial _{1}} |\omega |^{2 k ^{j}} \right) ^{\frac{1}{2k^{3}}}.\]
%
Then we get 
%
\[ I_1 \leq C ^{\frac{1}{k^{i-1}}}  k ^{i-1} + C ^{\frac{1}{k^{i-1}}}  (4 k)  ^{\frac{1}{k^{i-1}}}I_{i-1}.\]
Using the standard iteration we get 
%
\[ I_i \leq C + \frac{1}{2k ^i} .\]
%
For any $ q \geq 2  $ let $j$ be such that 
%
\[ 2 \kappa ^{i-1} \leq q \leq 2\kappa^{ j}.\]
%
Using H\"{o}lder and $ || \omega ||_{L^{2}} \leq C $ we get 
%
\[\Vert \omega \Vert_{L^{q}} C I_j \leq \tilde{C} q \; \geq 2.\]
%
Since $ q ^q \leq e^q q !$, we have 
%
\[\int_{B_{1}} |\omega | ^q \leq \tilde{C} ^q q ^q \leq ( \tilde{C} e ^q) q !.\]
%
For $ \varepsilon$ enough
%
\[\int_{B_{1}} e ^{\varepsilon |\omega|} \leq \sum^\infty_{q = 2} (C \varepsilon e )^q \leq C .\]
%
This proved the weak Harnack inequality.

\begin{theorem} [Harnack inequality] Let $u$ be a positive harmonic function on $ B(a)$. Then for any $ 0 < \theta < 1 $ we have 
%
\[\sup _{B(a\theta)} u \leq C \inf_{B(a \theta) }u \]
%
where $C$ only depends on $n, (1 - \theta )^{-1} $, and the Sobolev constants.
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
